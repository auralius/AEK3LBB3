{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c96c1290-5d85-4091-9b8c-d62a327b8e9e",
   "metadata": {},
   "source": [
    "# Multiclass Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8c67aa-88ec-47aa-8e4c-d5e774573d79",
   "metadata": {},
   "source": [
    "**This material is heavily based on the popular Standford CS231n lecture material.** [Please check on their website for more detailed information](https://cs231n.github.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e26eb164-b0be-4131-bc19-a9133d8108f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Times\",\n",
    "    \"font.size\": 10,\n",
    "})\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a221dbf",
   "metadata": {},
   "source": [
    "## Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b485a5-d495-48ed-ab6f-fcbd5bbe8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import * \n",
    "\n",
    "class SVM():\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "\n",
    "    \n",
    "    def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100, batch_size=200, verbose=True):\n",
    "        '''\n",
    "        Train this linear classifier using stochastic gradient descent.\n",
    "\n",
    "        Inputs:\n",
    "        - X: A numpy array of shape (N, D) containing training data; there are N\n",
    "          training samples each of dimension D.\n",
    "        - y: A numpy array of shape (N,) containing training labels; y[i] = c\n",
    "          means that X[i] has label 0 <= c < C for C classes.\n",
    "        - learning_rate: (float) learning rate for optimization.\n",
    "        - reg: (float) regularization strength.\n",
    "        - num_iters: (integer) number of steps to take when optimizing\n",
    "        - batch_size: (integer) number of training examples to use at each step.\n",
    "        - verbose: (boolean) If true, print progress during optimization.\n",
    "\n",
    "        Outputs:\n",
    "        A list containing the value of the loss function at each training iteration.\n",
    "        '''\n",
    "          \n",
    "        num_train, dim = X.shape\n",
    "        num_classes = len(np.unique(y)) \n",
    "        if self.W is None:\n",
    "            # lazily initialize W\n",
    "            self.W = 0.001 * np.random.randn(dim, num_classes)\n",
    "\n",
    "        # Run stochastic gradient descent to optimize W\n",
    "        loss_history = []\n",
    "        for it in range(num_iters):\n",
    "            X_batch = None\n",
    "            y_batch = None\n",
    "\n",
    "            # Sample batch_size elements from the training data and their           \n",
    "            # corresponding labels to use in this round of gradient descent.        \n",
    "            # Store the data in X_batch and their corresponding labels in           \n",
    "            # y_batch; after sampling X_batch should have shape (dim, batch_size)   \n",
    "            # and y_batch should have shape (batch_size,)                           \n",
    "            \n",
    "            batch_indices = np.random.choice(num_train, batch_size, replace=False)\n",
    "            X_batch = X[batch_indices]\n",
    "            y_batch = y[batch_indices]\n",
    "            \n",
    "            # evaluate loss and gradient\n",
    "            loss, grad = svm_loss(self.W, X_batch, y_batch, reg)\n",
    "            loss_history.append(loss)\n",
    "\n",
    "            # Update the weights using the gradient and the learning rate.          \n",
    "            self.W = self.W - learning_rate * grad\n",
    "     \n",
    "            if verbose and it % 10 == 0:\n",
    "                print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
    "\n",
    "            if loss < 1.0:\n",
    "                break\n",
    "\n",
    "        return loss_history\n",
    "    \n",
    "\n",
    "    def predict(self, X, k=1, L=2):\n",
    "        \"\"\"\n",
    "        Use the trained weights of this linear classifier to predict labels for\n",
    "        data points.\n",
    "\n",
    "        Inputs:\n",
    "        - X: A numpy array of shape (N, D) containing training data; there are N\n",
    "          training samples each of dimension D.\n",
    "\n",
    "        Returns:\n",
    "        - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional\n",
    "          array of length N, and each element is an integer giving the predicted\n",
    "          class.\n",
    "        \"\"\"\n",
    "        \n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        scores = X.dot(self.W)\n",
    "        y_pred = scores.argmax(axis=1)\n",
    "\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de966bf",
   "metadata": {},
   "source": [
    "## Breast Cancer Wisconsin\n",
    "\n",
    "We are going to use the Diagnostic Wisconsin breast cancer dataset is available in public domain.\n",
    "\n",
    "We obtained the dataset from the following link:  \n",
    "\n",
    "https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic\n",
    "\n",
    "\n",
    "This dataset is also available in scikit-learn:  \n",
    "\n",
    "https://scikit-learn.org/1.5/modules/generated/sklearn.datasets.load_breast_cancer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb01b45",
   "metadata": {},
   "source": [
    "The original labels are characters: `M` and `B`. For the SVM to work, the labels must be numbers. Hence, we change the labels:\n",
    "* `M` is replaced with `1`\n",
    "* `B` is replaced with `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d51e722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension numbers : 30\n",
      "Number of data    : 569\n",
      "Labels            : [0 1]\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"./datasets/breast_cancer/wdbc.data\", delimiter=\",\", dtype=str)\n",
    "X = np.float32(data[:, 2:])  # 10 dimensions\n",
    "\n",
    "# Diagnosis (M = malignant, B = benign)\n",
    "y = np.zeros(X.shape[0], dtype=np.int32) \n",
    "y[np.where(data[:,1]=='M')] = 1\n",
    "y[np.where(data[:,1]=='B')] = 0\n",
    "\n",
    "print(\"Dimension numbers :\", X.shape[1])\n",
    "print(\"Number of data    :\", X.shape[0])\n",
    "print(\"Labels            :\", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca1bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:400, :]\n",
    "y_train = y[0:400]\n",
    "X_test  = X[401:, :]\n",
    "y_test  = y[401:]\n",
    "\n",
    "num_test = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0389410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 10000: loss 1.784581\n",
      "iteration 10 / 10000: loss 462.868756\n",
      "iteration 20 / 10000: loss 363.492101\n",
      "iteration 30 / 10000: loss 167.398950\n",
      "iteration 40 / 10000: loss 369.175356\n",
      "iteration 50 / 10000: loss 17.617184\n",
      "iteration 60 / 10000: loss 386.623835\n",
      "iteration 70 / 10000: loss 308.352671\n",
      "iteration 80 / 10000: loss 87.915069\n",
      "iteration 90 / 10000: loss 101.372292\n",
      "iteration 100 / 10000: loss 29.703263\n",
      "iteration 110 / 10000: loss 17.998642\n",
      "iteration 120 / 10000: loss 131.297833\n",
      "iteration 130 / 10000: loss 148.432137\n",
      "iteration 140 / 10000: loss 81.965541\n",
      "iteration 150 / 10000: loss 84.479955\n",
      "iteration 160 / 10000: loss 69.091878\n",
      "iteration 170 / 10000: loss 15.848667\n",
      "iteration 180 / 10000: loss 8.246587\n",
      "iteration 190 / 10000: loss 13.840735\n",
      "iteration 200 / 10000: loss 13.663609\n",
      "iteration 210 / 10000: loss 11.517691\n",
      "iteration 220 / 10000: loss 16.811609\n",
      "iteration 230 / 10000: loss 10.883426\n",
      "iteration 240 / 10000: loss 13.705744\n",
      "iteration 250 / 10000: loss 8.197055\n",
      "iteration 260 / 10000: loss 10.547570\n",
      "iteration 270 / 10000: loss 13.072680\n",
      "iteration 280 / 10000: loss 14.197346\n",
      "iteration 290 / 10000: loss 5.372602\n",
      "iteration 300 / 10000: loss 64.525346\n",
      "iteration 310 / 10000: loss 29.409368\n",
      "iteration 320 / 10000: loss 34.400024\n",
      "iteration 330 / 10000: loss 10.844280\n",
      "iteration 340 / 10000: loss 18.057158\n",
      "iteration 350 / 10000: loss 10.215440\n",
      "iteration 360 / 10000: loss 9.054528\n",
      "iteration 370 / 10000: loss 22.043680\n",
      "iteration 380 / 10000: loss 11.184976\n",
      "iteration 390 / 10000: loss 14.636507\n",
      "iteration 400 / 10000: loss 8.329086\n",
      "iteration 410 / 10000: loss 10.933883\n",
      "iteration 420 / 10000: loss 7.497819\n",
      "iteration 430 / 10000: loss 5.004961\n",
      "iteration 440 / 10000: loss 6.636620\n",
      "iteration 450 / 10000: loss 6.065900\n",
      "iteration 460 / 10000: loss 5.960918\n",
      "iteration 470 / 10000: loss 33.687579\n",
      "iteration 480 / 10000: loss 13.949552\n",
      "iteration 490 / 10000: loss 9.242133\n",
      "iteration 500 / 10000: loss 3.789187\n",
      "iteration 510 / 10000: loss 19.261981\n",
      "iteration 520 / 10000: loss 100.465914\n",
      "iteration 530 / 10000: loss 21.359663\n",
      "iteration 540 / 10000: loss 7.821322\n",
      "iteration 550 / 10000: loss 6.701852\n",
      "iteration 560 / 10000: loss 9.190876\n",
      "iteration 570 / 10000: loss 9.947879\n",
      "iteration 580 / 10000: loss 6.307811\n",
      "iteration 590 / 10000: loss 9.587600\n",
      "iteration 600 / 10000: loss 3.002520\n",
      "iteration 610 / 10000: loss 18.435634\n",
      "iteration 620 / 10000: loss 65.686568\n",
      "iteration 630 / 10000: loss 58.764839\n",
      "iteration 640 / 10000: loss 18.941049\n",
      "iteration 650 / 10000: loss 4.170855\n",
      "iteration 660 / 10000: loss 7.273783\n",
      "iteration 670 / 10000: loss 9.827601\n",
      "iteration 680 / 10000: loss 5.169834\n",
      "iteration 690 / 10000: loss 17.030269\n",
      "iteration 700 / 10000: loss 7.268623\n",
      "iteration 710 / 10000: loss 6.590913\n",
      "iteration 720 / 10000: loss 8.587258\n",
      "iteration 730 / 10000: loss 13.312774\n",
      "iteration 740 / 10000: loss 11.364569\n",
      "iteration 750 / 10000: loss 5.073383\n",
      "iteration 760 / 10000: loss 10.525819\n",
      "iteration 770 / 10000: loss 6.671091\n",
      "iteration 780 / 10000: loss 5.797679\n",
      "iteration 790 / 10000: loss 7.077413\n",
      "iteration 800 / 10000: loss 20.231664\n",
      "iteration 810 / 10000: loss 5.498037\n",
      "iteration 820 / 10000: loss 7.965978\n",
      "iteration 830 / 10000: loss 6.353414\n",
      "iteration 840 / 10000: loss 8.607149\n",
      "iteration 850 / 10000: loss 5.511686\n",
      "iteration 860 / 10000: loss 7.781281\n",
      "iteration 870 / 10000: loss 14.243985\n",
      "iteration 880 / 10000: loss 9.673541\n",
      "iteration 890 / 10000: loss 23.149126\n",
      "iteration 900 / 10000: loss 104.049632\n",
      "iteration 910 / 10000: loss 7.501164\n",
      "iteration 920 / 10000: loss 10.243575\n",
      "iteration 930 / 10000: loss 6.368958\n",
      "iteration 940 / 10000: loss 8.956705\n",
      "iteration 950 / 10000: loss 8.264422\n",
      "iteration 960 / 10000: loss 6.918301\n",
      "iteration 970 / 10000: loss 11.016098\n",
      "iteration 980 / 10000: loss 6.947366\n",
      "iteration 990 / 10000: loss 35.396678\n",
      "iteration 1000 / 10000: loss 50.030231\n",
      "iteration 1010 / 10000: loss 68.138482\n",
      "iteration 1020 / 10000: loss 17.839665\n",
      "iteration 1030 / 10000: loss 8.331517\n",
      "iteration 1040 / 10000: loss 9.474812\n",
      "iteration 1050 / 10000: loss 8.250811\n",
      "iteration 1060 / 10000: loss 8.456991\n",
      "iteration 1070 / 10000: loss 5.326201\n",
      "iteration 1080 / 10000: loss 8.697916\n",
      "iteration 1090 / 10000: loss 6.444706\n",
      "iteration 1100 / 10000: loss 7.334272\n",
      "iteration 1110 / 10000: loss 3.728750\n",
      "iteration 1120 / 10000: loss 4.899574\n",
      "iteration 1130 / 10000: loss 6.332795\n",
      "iteration 1140 / 10000: loss 6.537759\n",
      "iteration 1150 / 10000: loss 7.647041\n",
      "iteration 1160 / 10000: loss 66.563092\n",
      "iteration 1170 / 10000: loss 6.203019\n",
      "iteration 1180 / 10000: loss 8.525119\n",
      "iteration 1190 / 10000: loss 13.994005\n",
      "iteration 1200 / 10000: loss 3.611461\n",
      "iteration 1210 / 10000: loss 7.193333\n",
      "iteration 1220 / 10000: loss 6.035938\n",
      "iteration 1230 / 10000: loss 4.946132\n",
      "iteration 1240 / 10000: loss 10.932809\n",
      "iteration 1250 / 10000: loss 6.305673\n",
      "iteration 1260 / 10000: loss 6.560661\n",
      "iteration 1270 / 10000: loss 8.468793\n",
      "iteration 1280 / 10000: loss 15.156626\n",
      "iteration 1290 / 10000: loss 4.961070\n",
      "iteration 1300 / 10000: loss 7.761939\n",
      "iteration 1310 / 10000: loss 6.980743\n",
      "iteration 1320 / 10000: loss 6.768702\n",
      "iteration 1330 / 10000: loss 4.989058\n",
      "iteration 1340 / 10000: loss 8.670429\n",
      "iteration 1350 / 10000: loss 7.103635\n",
      "iteration 1360 / 10000: loss 8.243091\n",
      "iteration 1370 / 10000: loss 9.045104\n",
      "iteration 1380 / 10000: loss 11.794447\n",
      "iteration 1390 / 10000: loss 5.565142\n",
      "iteration 1400 / 10000: loss 8.760235\n",
      "iteration 1410 / 10000: loss 6.295952\n",
      "iteration 1420 / 10000: loss 6.994142\n",
      "iteration 1430 / 10000: loss 6.223975\n",
      "iteration 1440 / 10000: loss 4.820727\n",
      "iteration 1450 / 10000: loss 7.175658\n",
      "iteration 1460 / 10000: loss 19.098771\n",
      "iteration 1470 / 10000: loss 16.661980\n",
      "iteration 1480 / 10000: loss 9.607784\n",
      "iteration 1490 / 10000: loss 4.885037\n",
      "iteration 1500 / 10000: loss 6.082175\n",
      "iteration 1510 / 10000: loss 83.695146\n",
      "iteration 1520 / 10000: loss 12.136779\n",
      "iteration 1530 / 10000: loss 7.099701\n",
      "iteration 1540 / 10000: loss 8.070696\n",
      "iteration 1550 / 10000: loss 6.025432\n",
      "iteration 1560 / 10000: loss 6.538472\n",
      "iteration 1570 / 10000: loss 15.141354\n",
      "iteration 1580 / 10000: loss 45.316390\n",
      "iteration 1590 / 10000: loss 38.116664\n",
      "iteration 1600 / 10000: loss 68.517075\n",
      "iteration 1610 / 10000: loss 11.291557\n",
      "iteration 1620 / 10000: loss 6.782438\n",
      "iteration 1630 / 10000: loss 8.202661\n",
      "iteration 1640 / 10000: loss 11.530650\n",
      "iteration 1650 / 10000: loss 60.132851\n",
      "iteration 1660 / 10000: loss 16.395115\n",
      "iteration 1670 / 10000: loss 15.902737\n",
      "iteration 1680 / 10000: loss 4.653503\n",
      "iteration 1690 / 10000: loss 6.916363\n",
      "iteration 1700 / 10000: loss 11.806863\n",
      "iteration 1710 / 10000: loss 5.345557\n",
      "iteration 1720 / 10000: loss 6.285590\n",
      "iteration 1730 / 10000: loss 4.408904\n",
      "iteration 1740 / 10000: loss 6.033533\n",
      "iteration 1750 / 10000: loss 5.448612\n",
      "iteration 1760 / 10000: loss 7.884416\n",
      "iteration 1770 / 10000: loss 8.416081\n",
      "iteration 1780 / 10000: loss 5.611530\n",
      "iteration 1790 / 10000: loss 6.203682\n",
      "iteration 1800 / 10000: loss 8.817046\n",
      "iteration 1810 / 10000: loss 4.352720\n",
      "iteration 1820 / 10000: loss 3.441671\n",
      "iteration 1830 / 10000: loss 5.512057\n",
      "iteration 1840 / 10000: loss 5.753140\n",
      "iteration 1850 / 10000: loss 5.886817\n",
      "iteration 1860 / 10000: loss 6.696653\n",
      "iteration 1870 / 10000: loss 7.509543\n",
      "iteration 1880 / 10000: loss 8.413028\n",
      "iteration 1890 / 10000: loss 151.483159\n",
      "iteration 1900 / 10000: loss 32.917620\n",
      "iteration 1910 / 10000: loss 33.624995\n",
      "iteration 1920 / 10000: loss 7.112660\n",
      "iteration 1930 / 10000: loss 5.751089\n",
      "iteration 1940 / 10000: loss 7.151047\n",
      "iteration 1950 / 10000: loss 5.572792\n",
      "iteration 1960 / 10000: loss 6.033612\n",
      "iteration 1970 / 10000: loss 8.396542\n",
      "iteration 1980 / 10000: loss 6.343711\n",
      "iteration 1990 / 10000: loss 5.561993\n",
      "iteration 2000 / 10000: loss 5.587618\n",
      "iteration 2010 / 10000: loss 5.273344\n",
      "iteration 2020 / 10000: loss 9.273591\n",
      "iteration 2030 / 10000: loss 5.813212\n",
      "iteration 2040 / 10000: loss 6.719498\n",
      "iteration 2050 / 10000: loss 7.481610\n",
      "iteration 2060 / 10000: loss 11.705810\n",
      "iteration 2070 / 10000: loss 3.467726\n",
      "iteration 2080 / 10000: loss 7.911339\n",
      "iteration 2090 / 10000: loss 140.863410\n",
      "iteration 2100 / 10000: loss 73.450056\n",
      "iteration 2110 / 10000: loss 7.589278\n",
      "iteration 2120 / 10000: loss 7.975531\n",
      "iteration 2130 / 10000: loss 5.624769\n",
      "iteration 2140 / 10000: loss 6.491556\n",
      "iteration 2150 / 10000: loss 6.502619\n",
      "iteration 2160 / 10000: loss 9.813922\n",
      "iteration 2170 / 10000: loss 5.419277\n",
      "iteration 2180 / 10000: loss 7.373215\n",
      "iteration 2190 / 10000: loss 6.550403\n",
      "iteration 2200 / 10000: loss 5.751323\n",
      "iteration 2210 / 10000: loss 12.090955\n",
      "iteration 2220 / 10000: loss 7.905072\n",
      "iteration 2230 / 10000: loss 5.444222\n",
      "iteration 2240 / 10000: loss 6.426785\n",
      "iteration 2250 / 10000: loss 8.243326\n",
      "iteration 2260 / 10000: loss 13.442389\n",
      "iteration 2270 / 10000: loss 28.821328\n",
      "iteration 2280 / 10000: loss 8.873500\n",
      "iteration 2290 / 10000: loss 4.302831\n",
      "iteration 2300 / 10000: loss 9.739441\n",
      "iteration 2310 / 10000: loss 99.245388\n",
      "iteration 2320 / 10000: loss 38.821175\n",
      "iteration 2330 / 10000: loss 5.251787\n",
      "iteration 2340 / 10000: loss 8.193031\n",
      "iteration 2350 / 10000: loss 4.829934\n",
      "iteration 2360 / 10000: loss 15.618288\n",
      "iteration 2370 / 10000: loss 7.845819\n",
      "iteration 2380 / 10000: loss 6.716712\n",
      "iteration 2390 / 10000: loss 3.423683\n",
      "iteration 2400 / 10000: loss 8.492911\n",
      "iteration 2410 / 10000: loss 6.565203\n",
      "iteration 2420 / 10000: loss 7.329633\n",
      "iteration 2430 / 10000: loss 5.254162\n",
      "iteration 2440 / 10000: loss 11.166502\n",
      "iteration 2450 / 10000: loss 5.960142\n",
      "iteration 2460 / 10000: loss 6.404990\n",
      "iteration 2470 / 10000: loss 9.237135\n",
      "iteration 2480 / 10000: loss 6.738665\n",
      "iteration 2490 / 10000: loss 6.156832\n",
      "iteration 2500 / 10000: loss 5.393921\n",
      "iteration 2510 / 10000: loss 7.716775\n",
      "iteration 2520 / 10000: loss 4.574444\n",
      "iteration 2530 / 10000: loss 6.123258\n",
      "iteration 2540 / 10000: loss 8.037782\n",
      "iteration 2550 / 10000: loss 9.942539\n",
      "iteration 2560 / 10000: loss 16.440577\n",
      "iteration 2570 / 10000: loss 5.226020\n",
      "iteration 2580 / 10000: loss 7.359874\n",
      "iteration 2590 / 10000: loss 12.611257\n",
      "iteration 2600 / 10000: loss 11.820015\n",
      "iteration 2610 / 10000: loss 6.574267\n",
      "iteration 2620 / 10000: loss 5.287526\n",
      "iteration 2630 / 10000: loss 21.465379\n",
      "iteration 2640 / 10000: loss 118.079481\n",
      "iteration 2650 / 10000: loss 14.964380\n",
      "iteration 2660 / 10000: loss 7.221819\n",
      "iteration 2670 / 10000: loss 5.143821\n",
      "iteration 2680 / 10000: loss 10.362011\n",
      "iteration 2690 / 10000: loss 5.642037\n",
      "iteration 2700 / 10000: loss 5.915723\n",
      "iteration 2710 / 10000: loss 4.789407\n",
      "iteration 2720 / 10000: loss 5.976382\n",
      "iteration 2730 / 10000: loss 6.821621\n",
      "iteration 2740 / 10000: loss 9.630144\n",
      "iteration 2750 / 10000: loss 9.829493\n",
      "iteration 2760 / 10000: loss 4.687306\n",
      "iteration 2770 / 10000: loss 9.095074\n",
      "iteration 2780 / 10000: loss 5.738011\n",
      "iteration 2790 / 10000: loss 8.591387\n",
      "iteration 2800 / 10000: loss 6.595956\n",
      "iteration 2810 / 10000: loss 6.937838\n",
      "iteration 2820 / 10000: loss 6.374559\n",
      "iteration 2830 / 10000: loss 5.099846\n",
      "iteration 2840 / 10000: loss 7.020654\n",
      "iteration 2850 / 10000: loss 6.056831\n",
      "iteration 2860 / 10000: loss 5.709967\n",
      "iteration 2870 / 10000: loss 110.099385\n",
      "iteration 2880 / 10000: loss 96.015220\n",
      "iteration 2890 / 10000: loss 24.749053\n",
      "iteration 2900 / 10000: loss 7.033755\n",
      "iteration 2910 / 10000: loss 5.769132\n",
      "iteration 2920 / 10000: loss 9.673947\n",
      "iteration 2930 / 10000: loss 7.139381\n",
      "iteration 2940 / 10000: loss 6.810677\n",
      "iteration 2950 / 10000: loss 7.523055\n",
      "iteration 2960 / 10000: loss 6.393656\n",
      "iteration 2970 / 10000: loss 12.780848\n",
      "iteration 2980 / 10000: loss 4.641417\n",
      "iteration 2990 / 10000: loss 5.348770\n",
      "iteration 3000 / 10000: loss 5.179504\n",
      "iteration 3010 / 10000: loss 8.621273\n",
      "iteration 3020 / 10000: loss 6.479276\n",
      "iteration 3030 / 10000: loss 12.462093\n",
      "iteration 3040 / 10000: loss 8.912574\n",
      "iteration 3050 / 10000: loss 5.768468\n",
      "iteration 3060 / 10000: loss 5.838804\n",
      "iteration 3070 / 10000: loss 3.954078\n",
      "iteration 3080 / 10000: loss 6.807539\n",
      "iteration 3090 / 10000: loss 7.673491\n",
      "iteration 3100 / 10000: loss 7.511932\n",
      "iteration 3110 / 10000: loss 8.271541\n",
      "iteration 3120 / 10000: loss 7.771045\n",
      "iteration 3130 / 10000: loss 9.433193\n",
      "iteration 3140 / 10000: loss 5.712735\n",
      "iteration 3150 / 10000: loss 16.165656\n",
      "iteration 3160 / 10000: loss 13.239340\n",
      "iteration 3170 / 10000: loss 74.619213\n",
      "iteration 3180 / 10000: loss 26.468755\n",
      "iteration 3190 / 10000: loss 6.731872\n",
      "iteration 3200 / 10000: loss 6.773537\n",
      "iteration 3210 / 10000: loss 5.737852\n",
      "iteration 3220 / 10000: loss 5.162830\n",
      "iteration 3230 / 10000: loss 6.491057\n",
      "iteration 3240 / 10000: loss 6.504041\n",
      "iteration 3250 / 10000: loss 4.893204\n",
      "iteration 3260 / 10000: loss 3.708556\n",
      "iteration 3270 / 10000: loss 6.160343\n",
      "iteration 3280 / 10000: loss 10.941095\n",
      "iteration 3290 / 10000: loss 8.156473\n",
      "iteration 3300 / 10000: loss 4.865146\n",
      "iteration 3310 / 10000: loss 6.349787\n",
      "iteration 3320 / 10000: loss 4.761853\n",
      "iteration 3330 / 10000: loss 6.792370\n",
      "iteration 3340 / 10000: loss 5.685337\n",
      "iteration 3350 / 10000: loss 4.532075\n",
      "iteration 3360 / 10000: loss 6.179401\n",
      "iteration 3370 / 10000: loss 7.295013\n",
      "iteration 3380 / 10000: loss 5.856883\n",
      "iteration 3390 / 10000: loss 6.956898\n",
      "iteration 3400 / 10000: loss 8.076114\n",
      "iteration 3410 / 10000: loss 6.430496\n",
      "iteration 3420 / 10000: loss 5.739319\n",
      "iteration 3430 / 10000: loss 6.791112\n",
      "iteration 3440 / 10000: loss 7.087100\n",
      "iteration 3450 / 10000: loss 5.097112\n",
      "iteration 3460 / 10000: loss 7.760504\n",
      "iteration 3470 / 10000: loss 5.474893\n",
      "iteration 3480 / 10000: loss 5.175798\n",
      "iteration 3490 / 10000: loss 6.076161\n",
      "iteration 3500 / 10000: loss 5.324574\n",
      "iteration 3510 / 10000: loss 4.343450\n",
      "iteration 3520 / 10000: loss 6.941100\n",
      "iteration 3530 / 10000: loss 7.424224\n",
      "iteration 3540 / 10000: loss 5.624716\n",
      "iteration 3550 / 10000: loss 30.980242\n",
      "iteration 3560 / 10000: loss 52.508543\n",
      "iteration 3570 / 10000: loss 80.879847\n",
      "iteration 3580 / 10000: loss 80.182314\n",
      "iteration 3590 / 10000: loss 42.737137\n",
      "iteration 3600 / 10000: loss 6.479823\n",
      "iteration 3610 / 10000: loss 5.355513\n",
      "iteration 3620 / 10000: loss 6.804483\n",
      "iteration 3630 / 10000: loss 7.696608\n",
      "iteration 3640 / 10000: loss 16.006590\n",
      "iteration 3650 / 10000: loss 3.653337\n",
      "iteration 3660 / 10000: loss 7.565375\n",
      "iteration 3670 / 10000: loss 5.891459\n",
      "iteration 3680 / 10000: loss 4.223524\n",
      "iteration 3690 / 10000: loss 5.841230\n",
      "iteration 3700 / 10000: loss 3.613715\n",
      "iteration 3710 / 10000: loss 4.892413\n",
      "iteration 3720 / 10000: loss 6.635461\n",
      "iteration 3730 / 10000: loss 7.612439\n",
      "iteration 3740 / 10000: loss 11.101005\n",
      "iteration 3750 / 10000: loss 8.949611\n",
      "iteration 3760 / 10000: loss 9.677294\n",
      "iteration 3770 / 10000: loss 8.279663\n",
      "iteration 3780 / 10000: loss 6.646307\n",
      "iteration 3790 / 10000: loss 7.133579\n",
      "iteration 3800 / 10000: loss 3.515878\n",
      "iteration 3810 / 10000: loss 8.249275\n",
      "iteration 3820 / 10000: loss 6.670143\n",
      "iteration 3830 / 10000: loss 5.254482\n",
      "iteration 3840 / 10000: loss 5.068012\n",
      "iteration 3850 / 10000: loss 6.529633\n",
      "iteration 3860 / 10000: loss 11.892043\n",
      "iteration 3870 / 10000: loss 19.297055\n",
      "iteration 3880 / 10000: loss 6.054497\n",
      "iteration 3890 / 10000: loss 6.151630\n",
      "iteration 3900 / 10000: loss 5.158313\n",
      "iteration 3910 / 10000: loss 36.244463\n",
      "iteration 3920 / 10000: loss 56.147347\n",
      "iteration 3930 / 10000: loss 24.451993\n",
      "iteration 3940 / 10000: loss 9.314679\n",
      "iteration 3950 / 10000: loss 8.043802\n",
      "iteration 3960 / 10000: loss 3.305811\n",
      "iteration 3970 / 10000: loss 9.735101\n",
      "iteration 3980 / 10000: loss 6.015881\n",
      "iteration 3990 / 10000: loss 8.261738\n",
      "iteration 4000 / 10000: loss 8.158433\n",
      "iteration 4010 / 10000: loss 8.636388\n",
      "iteration 4020 / 10000: loss 3.908099\n",
      "iteration 4030 / 10000: loss 3.506528\n",
      "iteration 4040 / 10000: loss 6.756895\n",
      "iteration 4050 / 10000: loss 8.800304\n",
      "iteration 4060 / 10000: loss 6.514537\n",
      "iteration 4070 / 10000: loss 6.098634\n",
      "iteration 4080 / 10000: loss 4.359789\n",
      "iteration 4090 / 10000: loss 7.739043\n",
      "iteration 4100 / 10000: loss 8.323776\n",
      "iteration 4110 / 10000: loss 5.666649\n",
      "iteration 4120 / 10000: loss 7.360283\n",
      "iteration 4130 / 10000: loss 3.479416\n",
      "iteration 4140 / 10000: loss 7.412195\n",
      "iteration 4150 / 10000: loss 4.359194\n",
      "iteration 4160 / 10000: loss 15.912928\n",
      "iteration 4170 / 10000: loss 6.282755\n",
      "iteration 4180 / 10000: loss 4.090033\n",
      "iteration 4190 / 10000: loss 6.325296\n",
      "iteration 4200 / 10000: loss 4.227636\n",
      "iteration 4210 / 10000: loss 7.826438\n",
      "iteration 4220 / 10000: loss 7.599506\n",
      "iteration 4230 / 10000: loss 97.692066\n",
      "iteration 4240 / 10000: loss 5.923214\n",
      "iteration 4250 / 10000: loss 5.438933\n",
      "iteration 4260 / 10000: loss 3.376390\n",
      "iteration 4270 / 10000: loss 15.480712\n",
      "iteration 4280 / 10000: loss 6.035409\n",
      "iteration 4290 / 10000: loss 11.617852\n",
      "iteration 4300 / 10000: loss 6.088567\n",
      "iteration 4310 / 10000: loss 4.122121\n",
      "iteration 4320 / 10000: loss 11.325321\n",
      "iteration 4330 / 10000: loss 6.974669\n",
      "iteration 4340 / 10000: loss 10.218961\n",
      "iteration 4350 / 10000: loss 5.742906\n",
      "iteration 4360 / 10000: loss 4.383592\n",
      "iteration 4370 / 10000: loss 5.957100\n",
      "iteration 4380 / 10000: loss 2.808388\n",
      "iteration 4390 / 10000: loss 6.489317\n",
      "iteration 4400 / 10000: loss 5.853680\n",
      "iteration 4410 / 10000: loss 7.773731\n",
      "iteration 4420 / 10000: loss 5.074648\n",
      "iteration 4430 / 10000: loss 16.295978\n",
      "iteration 4440 / 10000: loss 18.331717\n",
      "iteration 4450 / 10000: loss 3.756251\n",
      "iteration 4460 / 10000: loss 9.216067\n",
      "iteration 4470 / 10000: loss 10.151049\n",
      "iteration 4480 / 10000: loss 9.568254\n",
      "iteration 4490 / 10000: loss 113.467014\n",
      "iteration 4500 / 10000: loss 52.301273\n",
      "iteration 4510 / 10000: loss 4.410687\n",
      "iteration 4520 / 10000: loss 4.028198\n",
      "iteration 4530 / 10000: loss 6.156965\n",
      "iteration 4540 / 10000: loss 4.708247\n",
      "iteration 4550 / 10000: loss 7.938011\n",
      "iteration 4560 / 10000: loss 14.868330\n",
      "iteration 4570 / 10000: loss 5.928458\n",
      "iteration 4580 / 10000: loss 2.047058\n",
      "iteration 4590 / 10000: loss 3.861685\n",
      "iteration 4600 / 10000: loss 8.169197\n",
      "iteration 4610 / 10000: loss 5.320234\n",
      "iteration 4620 / 10000: loss 6.224487\n",
      "iteration 4630 / 10000: loss 5.824219\n",
      "iteration 4640 / 10000: loss 3.499869\n",
      "iteration 4650 / 10000: loss 4.658805\n",
      "iteration 4660 / 10000: loss 6.497331\n",
      "iteration 4670 / 10000: loss 6.782379\n",
      "iteration 4680 / 10000: loss 11.341197\n",
      "iteration 4690 / 10000: loss 8.422246\n",
      "iteration 4700 / 10000: loss 7.293363\n",
      "iteration 4710 / 10000: loss 5.121273\n",
      "iteration 4720 / 10000: loss 6.642257\n",
      "iteration 4730 / 10000: loss 4.525356\n",
      "iteration 4740 / 10000: loss 5.352810\n",
      "iteration 4750 / 10000: loss 10.187508\n",
      "iteration 4760 / 10000: loss 17.298930\n",
      "iteration 4770 / 10000: loss 14.039525\n",
      "iteration 4780 / 10000: loss 58.063698\n",
      "iteration 4790 / 10000: loss 10.279096\n",
      "iteration 4800 / 10000: loss 4.559625\n",
      "iteration 4810 / 10000: loss 11.064950\n",
      "iteration 4820 / 10000: loss 4.070101\n",
      "iteration 4830 / 10000: loss 6.308120\n",
      "iteration 4840 / 10000: loss 7.930704\n",
      "iteration 4850 / 10000: loss 6.969225\n",
      "iteration 4860 / 10000: loss 6.097603\n",
      "iteration 4870 / 10000: loss 6.620150\n",
      "iteration 4880 / 10000: loss 6.152962\n",
      "iteration 4890 / 10000: loss 4.962510\n",
      "iteration 4900 / 10000: loss 7.412347\n",
      "iteration 4910 / 10000: loss 4.527016\n",
      "iteration 4920 / 10000: loss 5.779068\n",
      "iteration 4930 / 10000: loss 12.800939\n",
      "iteration 4940 / 10000: loss 17.425089\n",
      "iteration 4950 / 10000: loss 8.931115\n",
      "iteration 4960 / 10000: loss 6.595283\n",
      "iteration 4970 / 10000: loss 7.640116\n",
      "iteration 4980 / 10000: loss 3.795232\n",
      "iteration 4990 / 10000: loss 7.640120\n",
      "iteration 5000 / 10000: loss 3.630835\n",
      "iteration 5010 / 10000: loss 3.585869\n",
      "iteration 5020 / 10000: loss 4.339072\n",
      "iteration 5030 / 10000: loss 8.161985\n",
      "iteration 5040 / 10000: loss 14.185098\n",
      "iteration 5050 / 10000: loss 7.505726\n",
      "iteration 5060 / 10000: loss 65.775891\n",
      "iteration 5070 / 10000: loss 45.995919\n",
      "iteration 5080 / 10000: loss 11.254916\n",
      "iteration 5090 / 10000: loss 5.929385\n",
      "iteration 5100 / 10000: loss 4.708745\n",
      "iteration 5110 / 10000: loss 4.642529\n",
      "iteration 5120 / 10000: loss 11.563339\n",
      "iteration 5130 / 10000: loss 5.498931\n",
      "iteration 5140 / 10000: loss 5.800499\n",
      "iteration 5150 / 10000: loss 6.439530\n",
      "iteration 5160 / 10000: loss 5.365597\n",
      "iteration 5170 / 10000: loss 7.172054\n",
      "iteration 5180 / 10000: loss 3.281745\n",
      "iteration 5190 / 10000: loss 5.253491\n",
      "iteration 5200 / 10000: loss 11.049150\n",
      "iteration 5210 / 10000: loss 12.118838\n",
      "iteration 5220 / 10000: loss 9.534690\n",
      "iteration 5230 / 10000: loss 7.345646\n",
      "iteration 5240 / 10000: loss 11.985428\n",
      "iteration 5250 / 10000: loss 64.093283\n",
      "iteration 5260 / 10000: loss 21.202364\n",
      "iteration 5270 / 10000: loss 6.933479\n",
      "iteration 5280 / 10000: loss 8.456215\n",
      "iteration 5290 / 10000: loss 4.974629\n",
      "iteration 5300 / 10000: loss 8.321570\n",
      "iteration 5310 / 10000: loss 7.194395\n",
      "iteration 5320 / 10000: loss 12.624317\n",
      "iteration 5330 / 10000: loss 8.182102\n",
      "iteration 5340 / 10000: loss 4.567178\n",
      "iteration 5350 / 10000: loss 6.096622\n",
      "iteration 5360 / 10000: loss 7.976748\n",
      "iteration 5370 / 10000: loss 8.363731\n",
      "iteration 5380 / 10000: loss 6.743830\n",
      "iteration 5390 / 10000: loss 4.260821\n",
      "iteration 5400 / 10000: loss 4.898526\n",
      "iteration 5410 / 10000: loss 15.703446\n",
      "iteration 5420 / 10000: loss 15.048358\n",
      "iteration 5430 / 10000: loss 14.947195\n",
      "iteration 5440 / 10000: loss 11.327900\n",
      "iteration 5450 / 10000: loss 4.375327\n",
      "iteration 5460 / 10000: loss 7.256397\n",
      "iteration 5470 / 10000: loss 6.232554\n",
      "iteration 5480 / 10000: loss 3.619918\n",
      "iteration 5490 / 10000: loss 9.470108\n",
      "iteration 5500 / 10000: loss 5.166509\n",
      "iteration 5510 / 10000: loss 13.470478\n",
      "iteration 5520 / 10000: loss 6.089203\n",
      "iteration 5530 / 10000: loss 5.362279\n",
      "iteration 5540 / 10000: loss 7.849627\n",
      "iteration 5550 / 10000: loss 8.867908\n",
      "iteration 5560 / 10000: loss 7.473808\n",
      "iteration 5570 / 10000: loss 5.403324\n",
      "iteration 5580 / 10000: loss 8.965609\n",
      "iteration 5590 / 10000: loss 5.373358\n",
      "iteration 5600 / 10000: loss 5.760081\n",
      "iteration 5610 / 10000: loss 7.653187\n",
      "iteration 5620 / 10000: loss 5.451906\n",
      "iteration 5630 / 10000: loss 6.161941\n",
      "iteration 5640 / 10000: loss 12.723358\n",
      "iteration 5650 / 10000: loss 5.140738\n",
      "iteration 5660 / 10000: loss 6.084765\n",
      "iteration 5670 / 10000: loss 5.112685\n",
      "iteration 5680 / 10000: loss 5.828641\n",
      "iteration 5690 / 10000: loss 14.543346\n",
      "iteration 5700 / 10000: loss 4.892450\n",
      "iteration 5710 / 10000: loss 5.872527\n",
      "iteration 5720 / 10000: loss 5.964146\n",
      "iteration 5730 / 10000: loss 3.390958\n",
      "iteration 5740 / 10000: loss 5.145522\n",
      "iteration 5750 / 10000: loss 18.989649\n",
      "iteration 5760 / 10000: loss 12.569601\n",
      "iteration 5770 / 10000: loss 4.036162\n",
      "iteration 5780 / 10000: loss 7.115983\n",
      "iteration 5790 / 10000: loss 3.588369\n",
      "iteration 5800 / 10000: loss 7.548003\n",
      "iteration 5810 / 10000: loss 11.378020\n",
      "iteration 5820 / 10000: loss 9.467179\n",
      "iteration 5830 / 10000: loss 7.024520\n",
      "iteration 5840 / 10000: loss 4.289713\n",
      "iteration 5850 / 10000: loss 2.941760\n",
      "iteration 5860 / 10000: loss 13.208916\n",
      "iteration 5870 / 10000: loss 5.999682\n",
      "iteration 5880 / 10000: loss 2.854774\n",
      "iteration 5890 / 10000: loss 4.085523\n",
      "iteration 5900 / 10000: loss 7.367528\n",
      "iteration 5910 / 10000: loss 5.274762\n",
      "iteration 5920 / 10000: loss 5.425038\n",
      "iteration 5930 / 10000: loss 4.560023\n",
      "iteration 5940 / 10000: loss 3.316661\n",
      "iteration 5950 / 10000: loss 3.512105\n",
      "iteration 5960 / 10000: loss 4.601075\n",
      "iteration 5970 / 10000: loss 6.338676\n",
      "iteration 5980 / 10000: loss 8.642084\n",
      "iteration 5990 / 10000: loss 28.782261\n",
      "iteration 6000 / 10000: loss 51.785181\n",
      "iteration 6010 / 10000: loss 19.489817\n",
      "iteration 6020 / 10000: loss 4.064424\n",
      "iteration 6030 / 10000: loss 5.042304\n",
      "iteration 6040 / 10000: loss 5.573593\n",
      "iteration 6050 / 10000: loss 5.021702\n",
      "iteration 6060 / 10000: loss 3.655730\n",
      "iteration 6070 / 10000: loss 4.981963\n",
      "iteration 6080 / 10000: loss 17.313589\n",
      "iteration 6090 / 10000: loss 4.361507\n",
      "iteration 6100 / 10000: loss 3.753642\n",
      "iteration 6110 / 10000: loss 8.641845\n",
      "iteration 6120 / 10000: loss 5.023069\n",
      "iteration 6130 / 10000: loss 6.085286\n",
      "iteration 6140 / 10000: loss 4.472397\n",
      "iteration 6150 / 10000: loss 6.482761\n",
      "iteration 6160 / 10000: loss 4.279091\n",
      "iteration 6170 / 10000: loss 7.385410\n",
      "iteration 6180 / 10000: loss 4.978854\n",
      "iteration 6190 / 10000: loss 10.014514\n",
      "iteration 6200 / 10000: loss 4.280557\n",
      "iteration 6210 / 10000: loss 6.759465\n",
      "iteration 6220 / 10000: loss 8.585295\n",
      "iteration 6230 / 10000: loss 4.208145\n",
      "iteration 6240 / 10000: loss 6.085583\n",
      "iteration 6250 / 10000: loss 5.641976\n",
      "iteration 6260 / 10000: loss 6.802261\n",
      "iteration 6270 / 10000: loss 11.665298\n",
      "iteration 6280 / 10000: loss 6.547227\n",
      "iteration 6290 / 10000: loss 6.630972\n",
      "iteration 6300 / 10000: loss 9.572583\n",
      "iteration 6310 / 10000: loss 8.210891\n",
      "iteration 6320 / 10000: loss 5.780743\n",
      "iteration 6330 / 10000: loss 20.398834\n",
      "iteration 6340 / 10000: loss 22.293212\n",
      "iteration 6350 / 10000: loss 25.452016\n",
      "iteration 6360 / 10000: loss 4.367125\n",
      "iteration 6370 / 10000: loss 8.803846\n",
      "iteration 6380 / 10000: loss 4.603269\n",
      "iteration 6390 / 10000: loss 6.135102\n",
      "iteration 6400 / 10000: loss 5.141067\n",
      "iteration 6410 / 10000: loss 10.308210\n",
      "iteration 6420 / 10000: loss 3.565672\n",
      "iteration 6430 / 10000: loss 5.791112\n",
      "iteration 6440 / 10000: loss 5.949571\n",
      "iteration 6450 / 10000: loss 6.019593\n",
      "iteration 6460 / 10000: loss 10.300938\n",
      "iteration 6470 / 10000: loss 85.629948\n",
      "iteration 6480 / 10000: loss 6.725514\n",
      "iteration 6490 / 10000: loss 3.941499\n",
      "iteration 6500 / 10000: loss 4.712899\n",
      "iteration 6510 / 10000: loss 5.178067\n",
      "iteration 6520 / 10000: loss 5.755733\n",
      "iteration 6530 / 10000: loss 5.211440\n",
      "iteration 6540 / 10000: loss 5.783411\n",
      "iteration 6550 / 10000: loss 6.679850\n",
      "iteration 6560 / 10000: loss 18.885767\n",
      "iteration 6570 / 10000: loss 5.570000\n",
      "iteration 6580 / 10000: loss 10.498876\n",
      "iteration 6590 / 10000: loss 4.456550\n",
      "iteration 6600 / 10000: loss 73.270221\n",
      "iteration 6610 / 10000: loss 98.310315\n",
      "iteration 6620 / 10000: loss 9.798309\n",
      "iteration 6630 / 10000: loss 4.924136\n",
      "iteration 6640 / 10000: loss 6.046307\n",
      "iteration 6650 / 10000: loss 10.092838\n",
      "iteration 6660 / 10000: loss 7.934928\n",
      "iteration 6670 / 10000: loss 4.860823\n",
      "iteration 6680 / 10000: loss 10.706433\n",
      "iteration 6690 / 10000: loss 8.811624\n",
      "iteration 6700 / 10000: loss 3.164182\n",
      "iteration 6710 / 10000: loss 6.208835\n",
      "iteration 6720 / 10000: loss 6.422658\n",
      "iteration 6730 / 10000: loss 8.570980\n",
      "iteration 6740 / 10000: loss 14.614634\n",
      "iteration 6750 / 10000: loss 5.613810\n",
      "iteration 6760 / 10000: loss 4.198459\n",
      "iteration 6770 / 10000: loss 11.038974\n",
      "iteration 6780 / 10000: loss 10.496269\n",
      "iteration 6790 / 10000: loss 9.075204\n",
      "iteration 6800 / 10000: loss 7.604761\n",
      "iteration 6810 / 10000: loss 6.010494\n",
      "iteration 6820 / 10000: loss 4.342361\n",
      "iteration 6830 / 10000: loss 8.015165\n",
      "iteration 6840 / 10000: loss 4.548263\n",
      "iteration 6850 / 10000: loss 7.082346\n",
      "iteration 6860 / 10000: loss 8.189660\n",
      "iteration 6870 / 10000: loss 13.194179\n",
      "iteration 6880 / 10000: loss 12.082353\n",
      "iteration 6890 / 10000: loss 5.586038\n",
      "iteration 6900 / 10000: loss 4.898442\n",
      "iteration 6910 / 10000: loss 4.384668\n",
      "iteration 6920 / 10000: loss 5.536823\n",
      "iteration 6930 / 10000: loss 5.510184\n",
      "iteration 6940 / 10000: loss 6.339195\n",
      "iteration 6950 / 10000: loss 6.945647\n",
      "iteration 6960 / 10000: loss 8.677504\n",
      "iteration 6970 / 10000: loss 7.302374\n",
      "iteration 6980 / 10000: loss 10.078912\n",
      "iteration 6990 / 10000: loss 5.145918\n",
      "iteration 7000 / 10000: loss 7.002844\n",
      "iteration 7010 / 10000: loss 3.922138\n",
      "iteration 7020 / 10000: loss 14.754519\n",
      "iteration 7030 / 10000: loss 7.413641\n",
      "iteration 7040 / 10000: loss 6.561494\n",
      "iteration 7050 / 10000: loss 26.000091\n",
      "iteration 7060 / 10000: loss 3.992284\n",
      "iteration 7070 / 10000: loss 5.193453\n",
      "iteration 7080 / 10000: loss 8.262413\n",
      "iteration 7090 / 10000: loss 3.638469\n",
      "iteration 7100 / 10000: loss 3.166318\n",
      "iteration 7110 / 10000: loss 5.310669\n",
      "iteration 7120 / 10000: loss 10.981488\n",
      "iteration 7130 / 10000: loss 3.524842\n",
      "iteration 7140 / 10000: loss 4.576268\n",
      "iteration 7150 / 10000: loss 24.235208\n",
      "iteration 7160 / 10000: loss 44.804817\n",
      "iteration 7170 / 10000: loss 75.113148\n",
      "iteration 7180 / 10000: loss 15.609939\n",
      "iteration 7190 / 10000: loss 4.029855\n",
      "iteration 7200 / 10000: loss 4.738415\n",
      "iteration 7210 / 10000: loss 6.849389\n",
      "iteration 7220 / 10000: loss 5.024009\n",
      "iteration 7230 / 10000: loss 7.061201\n",
      "iteration 7240 / 10000: loss 16.957143\n",
      "iteration 7250 / 10000: loss 5.185910\n",
      "iteration 7260 / 10000: loss 5.186522\n",
      "iteration 7270 / 10000: loss 3.682532\n",
      "iteration 7280 / 10000: loss 7.652517\n",
      "iteration 7290 / 10000: loss 4.253915\n",
      "iteration 7300 / 10000: loss 4.311093\n",
      "iteration 7310 / 10000: loss 5.683435\n",
      "iteration 7320 / 10000: loss 2.003756\n",
      "iteration 7330 / 10000: loss 4.369015\n",
      "iteration 7340 / 10000: loss 3.416879\n",
      "iteration 7350 / 10000: loss 5.488073\n",
      "iteration 7360 / 10000: loss 5.080309\n",
      "iteration 7370 / 10000: loss 4.655351\n",
      "iteration 7380 / 10000: loss 87.872677\n",
      "iteration 7390 / 10000: loss 7.697726\n",
      "iteration 7400 / 10000: loss 4.250393\n",
      "iteration 7410 / 10000: loss 3.857919\n",
      "iteration 7420 / 10000: loss 3.815384\n",
      "iteration 7430 / 10000: loss 4.942892\n",
      "iteration 7440 / 10000: loss 5.189302\n",
      "iteration 7450 / 10000: loss 6.495220\n",
      "iteration 7460 / 10000: loss 9.693466\n",
      "iteration 7470 / 10000: loss 5.561126\n",
      "iteration 7480 / 10000: loss 11.545331\n",
      "iteration 7490 / 10000: loss 4.461277\n",
      "iteration 7500 / 10000: loss 5.608825\n",
      "iteration 7510 / 10000: loss 5.406698\n",
      "iteration 7520 / 10000: loss 26.708155\n",
      "iteration 7530 / 10000: loss 7.700323\n",
      "iteration 7540 / 10000: loss 4.379238\n",
      "iteration 7550 / 10000: loss 9.221433\n",
      "iteration 7560 / 10000: loss 19.970156\n",
      "iteration 7570 / 10000: loss 34.392740\n",
      "iteration 7580 / 10000: loss 77.216366\n",
      "iteration 7590 / 10000: loss 5.564879\n",
      "iteration 7600 / 10000: loss 7.113041\n",
      "iteration 7610 / 10000: loss 5.182290\n",
      "iteration 7620 / 10000: loss 5.746494\n",
      "iteration 7630 / 10000: loss 6.119724\n",
      "iteration 7640 / 10000: loss 13.187142\n",
      "iteration 7650 / 10000: loss 7.440091\n",
      "iteration 7660 / 10000: loss 7.242842\n",
      "iteration 7670 / 10000: loss 6.004295\n",
      "iteration 7680 / 10000: loss 2.705066\n",
      "iteration 7690 / 10000: loss 5.198266\n",
      "iteration 7700 / 10000: loss 8.428644\n",
      "iteration 7710 / 10000: loss 6.927268\n",
      "iteration 7720 / 10000: loss 4.776998\n",
      "iteration 7730 / 10000: loss 5.580650\n",
      "iteration 7740 / 10000: loss 6.316689\n",
      "iteration 7750 / 10000: loss 11.490679\n",
      "iteration 7760 / 10000: loss 10.547930\n",
      "iteration 7770 / 10000: loss 4.602500\n",
      "iteration 7780 / 10000: loss 3.749329\n",
      "iteration 7790 / 10000: loss 8.941751\n",
      "iteration 7800 / 10000: loss 3.200313\n",
      "iteration 7810 / 10000: loss 2.100476\n",
      "iteration 7820 / 10000: loss 6.317286\n",
      "iteration 7830 / 10000: loss 7.001027\n",
      "iteration 7840 / 10000: loss 4.214698\n",
      "iteration 7850 / 10000: loss 6.786842\n",
      "iteration 7860 / 10000: loss 8.325512\n",
      "iteration 7870 / 10000: loss 4.452848\n",
      "iteration 7880 / 10000: loss 6.221530\n",
      "iteration 7890 / 10000: loss 5.008799\n",
      "iteration 7900 / 10000: loss 5.858165\n",
      "iteration 7910 / 10000: loss 11.016300\n",
      "iteration 7920 / 10000: loss 6.612327\n",
      "iteration 7930 / 10000: loss 6.848400\n",
      "iteration 7940 / 10000: loss 4.070547\n",
      "iteration 7950 / 10000: loss 5.762606\n",
      "iteration 7960 / 10000: loss 5.685096\n",
      "iteration 7970 / 10000: loss 5.676659\n",
      "iteration 7980 / 10000: loss 2.674134\n",
      "iteration 7990 / 10000: loss 4.467339\n",
      "iteration 8000 / 10000: loss 13.748464\n",
      "iteration 8010 / 10000: loss 6.129051\n",
      "iteration 8020 / 10000: loss 3.300460\n",
      "iteration 8030 / 10000: loss 11.248580\n",
      "iteration 8040 / 10000: loss 172.864376\n",
      "iteration 8050 / 10000: loss 7.431298\n",
      "iteration 8060 / 10000: loss 3.447493\n",
      "iteration 8070 / 10000: loss 7.171782\n",
      "iteration 8080 / 10000: loss 4.610037\n",
      "iteration 8090 / 10000: loss 3.516831\n",
      "iteration 8100 / 10000: loss 3.402676\n",
      "iteration 8110 / 10000: loss 5.594577\n",
      "iteration 8120 / 10000: loss 15.636113\n",
      "iteration 8130 / 10000: loss 9.360388\n",
      "iteration 8140 / 10000: loss 6.326422\n",
      "iteration 8150 / 10000: loss 4.203004\n",
      "iteration 8160 / 10000: loss 5.166348\n",
      "iteration 8170 / 10000: loss 9.337527\n",
      "iteration 8180 / 10000: loss 13.152119\n",
      "iteration 8190 / 10000: loss 6.401986\n",
      "iteration 8200 / 10000: loss 5.274465\n",
      "iteration 8210 / 10000: loss 7.726482\n",
      "iteration 8220 / 10000: loss 19.360096\n",
      "iteration 8230 / 10000: loss 32.615834\n",
      "iteration 8240 / 10000: loss 93.490251\n",
      "iteration 8250 / 10000: loss 66.034019\n",
      "iteration 8260 / 10000: loss 6.155322\n",
      "iteration 8270 / 10000: loss 4.167108\n",
      "iteration 8280 / 10000: loss 11.088352\n",
      "iteration 8290 / 10000: loss 4.139050\n",
      "iteration 8300 / 10000: loss 7.030519\n",
      "iteration 8310 / 10000: loss 4.819073\n",
      "iteration 8320 / 10000: loss 6.945698\n",
      "iteration 8330 / 10000: loss 6.681477\n",
      "iteration 8340 / 10000: loss 8.395281\n",
      "iteration 8350 / 10000: loss 7.751842\n",
      "iteration 8360 / 10000: loss 3.904187\n",
      "iteration 8370 / 10000: loss 4.854615\n",
      "iteration 8380 / 10000: loss 7.091208\n",
      "iteration 8390 / 10000: loss 2.112674\n",
      "iteration 8400 / 10000: loss 5.273169\n",
      "iteration 8410 / 10000: loss 3.955632\n",
      "iteration 8420 / 10000: loss 6.748953\n",
      "iteration 8430 / 10000: loss 4.128865\n",
      "iteration 8440 / 10000: loss 5.644386\n",
      "iteration 8450 / 10000: loss 10.733971\n",
      "iteration 8460 / 10000: loss 5.533608\n",
      "iteration 8470 / 10000: loss 5.119602\n",
      "iteration 8480 / 10000: loss 8.333351\n",
      "iteration 8490 / 10000: loss 9.049395\n",
      "iteration 8500 / 10000: loss 4.097537\n",
      "iteration 8510 / 10000: loss 3.941497\n",
      "iteration 8520 / 10000: loss 8.342113\n",
      "iteration 8530 / 10000: loss 7.763172\n",
      "iteration 8540 / 10000: loss 7.176206\n",
      "iteration 8550 / 10000: loss 12.061510\n",
      "iteration 8560 / 10000: loss 9.377955\n",
      "iteration 8570 / 10000: loss 7.687999\n",
      "iteration 8580 / 10000: loss 6.372711\n",
      "iteration 8590 / 10000: loss 4.256334\n",
      "iteration 8600 / 10000: loss 5.466043\n",
      "iteration 8610 / 10000: loss 9.379740\n",
      "iteration 8620 / 10000: loss 43.663045\n",
      "iteration 8630 / 10000: loss 73.355083\n",
      "iteration 8640 / 10000: loss 9.300249\n",
      "iteration 8650 / 10000: loss 4.326241\n",
      "iteration 8660 / 10000: loss 10.074841\n",
      "iteration 8670 / 10000: loss 4.512687\n",
      "iteration 8680 / 10000: loss 6.457984\n",
      "iteration 8690 / 10000: loss 5.430689\n",
      "iteration 8700 / 10000: loss 5.531730\n",
      "iteration 8710 / 10000: loss 7.669314\n",
      "iteration 8720 / 10000: loss 6.423450\n",
      "iteration 8730 / 10000: loss 5.494871\n",
      "iteration 8740 / 10000: loss 7.052004\n",
      "iteration 8750 / 10000: loss 4.807163\n",
      "iteration 8760 / 10000: loss 10.481597\n",
      "iteration 8770 / 10000: loss 7.735635\n",
      "iteration 8780 / 10000: loss 7.155378\n",
      "iteration 8790 / 10000: loss 4.543034\n",
      "iteration 8800 / 10000: loss 7.093061\n",
      "iteration 8810 / 10000: loss 3.393877\n",
      "iteration 8820 / 10000: loss 42.085238\n",
      "iteration 8830 / 10000: loss 44.378014\n",
      "iteration 8840 / 10000: loss 7.106892\n",
      "iteration 8850 / 10000: loss 4.464134\n",
      "iteration 8860 / 10000: loss 9.096442\n",
      "iteration 8870 / 10000: loss 5.809305\n",
      "iteration 8880 / 10000: loss 4.624320\n",
      "iteration 8890 / 10000: loss 2.516679\n",
      "iteration 8900 / 10000: loss 4.663015\n",
      "iteration 8910 / 10000: loss 8.759748\n",
      "iteration 8920 / 10000: loss 3.484642\n",
      "iteration 8930 / 10000: loss 4.422773\n",
      "iteration 8940 / 10000: loss 3.515740\n",
      "iteration 8950 / 10000: loss 4.648809\n",
      "iteration 8960 / 10000: loss 9.439469\n",
      "iteration 8970 / 10000: loss 5.164474\n",
      "iteration 8980 / 10000: loss 6.589120\n",
      "iteration 8990 / 10000: loss 4.527938\n",
      "iteration 9000 / 10000: loss 4.418427\n",
      "iteration 9010 / 10000: loss 13.574635\n",
      "iteration 9020 / 10000: loss 17.282910\n",
      "iteration 9030 / 10000: loss 4.502092\n",
      "iteration 9040 / 10000: loss 6.145178\n",
      "iteration 9050 / 10000: loss 9.637412\n",
      "iteration 9060 / 10000: loss 7.278034\n",
      "iteration 9070 / 10000: loss 6.377891\n",
      "iteration 9080 / 10000: loss 4.118144\n",
      "iteration 9090 / 10000: loss 4.468121\n",
      "iteration 9100 / 10000: loss 5.971702\n",
      "iteration 9110 / 10000: loss 7.862745\n",
      "iteration 9120 / 10000: loss 5.362656\n",
      "iteration 9130 / 10000: loss 9.730164\n",
      "iteration 9140 / 10000: loss 8.543861\n",
      "iteration 9150 / 10000: loss 5.509681\n",
      "iteration 9160 / 10000: loss 5.041351\n",
      "iteration 9170 / 10000: loss 5.584405\n",
      "iteration 9180 / 10000: loss 4.847475\n",
      "iteration 9190 / 10000: loss 5.717163\n",
      "iteration 9200 / 10000: loss 5.478392\n",
      "iteration 9210 / 10000: loss 8.306612\n",
      "iteration 9220 / 10000: loss 5.632214\n",
      "iteration 9230 / 10000: loss 11.244642\n",
      "iteration 9240 / 10000: loss 6.927016\n",
      "iteration 9250 / 10000: loss 13.495892\n",
      "iteration 9260 / 10000: loss 3.942920\n",
      "iteration 9270 / 10000: loss 4.954355\n",
      "iteration 9280 / 10000: loss 4.396501\n",
      "iteration 9290 / 10000: loss 11.002404\n",
      "iteration 9300 / 10000: loss 3.288608\n",
      "iteration 9310 / 10000: loss 9.808590\n",
      "iteration 9320 / 10000: loss 11.640917\n",
      "iteration 9330 / 10000: loss 3.660467\n",
      "iteration 9340 / 10000: loss 8.158627\n",
      "iteration 9350 / 10000: loss 33.540914\n",
      "iteration 9360 / 10000: loss 23.661102\n",
      "iteration 9370 / 10000: loss 33.634909\n",
      "iteration 9380 / 10000: loss 3.405458\n",
      "iteration 9390 / 10000: loss 4.412952\n",
      "iteration 9400 / 10000: loss 4.355099\n",
      "iteration 9410 / 10000: loss 4.046891\n",
      "iteration 9420 / 10000: loss 5.074341\n",
      "iteration 9430 / 10000: loss 0.986897\n"
     ]
    }
   ],
   "source": [
    "classifier = SVM()\n",
    "loss_hist = classifier.train(X_train, y_train, num_iters=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9446e7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGtCAYAAAABCu4VAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSGUlEQVR4nO3deXwb9Z038I9yORyx5YRSoEmJZVootJTICbTb7fZAKj233dYmT8+nzxbs0mPb7ZYEd4GW0jax6dILFmzSkzM4XAUKQXIIkAA5ZOciJCFSDuc+bFlOHJ+a5w9H4xlpNJqR5pQ+79crr8gazcxPo5nffOd3egRBEEBERETkYhPsTgARERFRoRjQEBERkesxoCEiIiLXY0BDRERErseAhoiIiFyPAQ0RERG5HgMaIiIicr1JdifACslkEgcOHMC0adPg8XjsTg4RERFpIAgC+vr6cMEFF2DCBPUymJIIaA4cOIBZs2bZnQwiIiLKQ1dXF2bOnKn6mZIIaKZNmwZg7ICUl5fbnBoiIiLSIpFIYNasWeJ9XE1JBDSpaqby8nIGNERERC6jpbkIGwUTERGR6zGgISIiItdjQENERESux4CGiIiIXI8BDREREbkeAxoiIiJyPQY0RERE5HoMaIiIiMj1GNAQERGR6zGgISIiItdjQENERESux4CGiIiIXI8BDREREbkeA5oCNT6+GTc9tsnuZBAREZU0BjQFiPcP4eG1e/HIui4cPzFod3KIiIhKFgOaAowmBfG15CURERFZjAENERERuR4DGiIiInI9BjRERETkegxoiIiIyPUY0BAREZHrMaAhIiIi12NAQ0RERK7HgIaIiIhcjwENERERuR4DGiIiInI9BjRERETkegxoiIiIyPUY0BAREZHrMaAhIiIi12NAYxABgt1JICIiKlkMaArg8XjsTgIRERGBAQ0REREVAQY0RERE5HqOCGji8bjdSSAiIiIXsy2gqa6uhsfjgcfjQV1dnfh+LBZDQ0MDWltbsXDhQtk6asuIiIiodE2yY6fhcBhNTU0IBAIAAK/XKy4LBoNoa2uD3+9HOBxGMBhEKBTKuYyIiIhKly0lNC0tLYjFYojFYrJgJhwOo7u7G36/HwAQCAQQDocRi8VUlxEREVFpsyWgicfjWLhwIWpqatDQ0CC+39HRgblz58o+6/P5EA6HVZelGxwcRCKRkP0z28rtR03fBxERESmzJaAJhUIQBAEtLS1obW1Fc3MzACAajcpKbICx6qhoNKq6LN2iRYtQUVEh/ps1a5ZZX0W0YNkm0/dBREREymzt5VRfX4+mpiYsXbrU0O02Njait7dX/NfV1WXo9omIiMhZbO+2XVtbK3bbrq6uzujCHY/HMW/ePNVl6crKylBeXi77R0RERMXL9oAGgNjQ1+/3ZzTyjcVi8Pv9qsvsIgicv4mIiMgJLA9oUj2WUlpaWtDY2AgAYjfuVOASDofh9/vh8/lUlxEREVFps3wcmlgshrq6OgQCAQSDQcyfP19WyhIKhdDU1ISamhpEIhG0t7drWkZERESlyyOUQL1JIpFARUUFent7DW1Pc/zEIGp+MV7atHvxZwzbNhERUanTc/92RBsaIiIiokIwoCmAx+OxOwlEREQEBjRERERUBBjQEBERkesxoCEiIiLXY0BDRERErseAxkA7DvfZnQQiIqKSxIDGQN/66zq7k0BERFSSGNAY6FjfkN1JICIiKkkMaIiIiMj1GNAQERGR6zGgISIiItdjQENERESux4CGiIiIXI8BDREREbkeAxoiIiJyPQY0RERE5HoMaIiIiMj1GNAUwJP296nhUVvSQUREVOoY0BAREZHrMaAhIiIi12NAQ0RERK7HgIaIiIhcjwENERERuR4DmgIIdieAiIiIADCgISIioiLAgIaIiIhcjwENERERuR4DGiIiInI9BjRERETkegxoiIiIyPUY0BAREZHrMaAhIiIi12NAQ0RERK7HgKYAHrsTQERERAAY0BAREVERYEBDRERErseAhoiIiFyPAQ0RERG5HgMaIiIicj0GNEREROR6DGiIiIjI9RjQEBERkesxoCEiIiLXY0BDRERErseAhoiIiFyPAQ0RERG5HgMaIiIicj0GNEREROR6DGiIiIjI9RjQEBERkevZHtDU1NQgHo+Lf8diMTQ0NKC1tRULFy6UfVZtmR08HrtTQERERAAwyc6dt7a2oqOjQ/ZeMBhEW1sb/H4/wuEwgsEgQqFQzmV2EATbdk1EREQStpXQSEtlUsLhMLq7u+H3+wEAgUAA4XAYsVhMdRkRERGVNtsCmkWLFqG+vl72XkdHB+bOnSt7z+fzIRwOqy4jIiKi0mZLlVM4HMb8+fMz3o9Go/B6vbL3vF4votEo4vF41mXpBgcHMTg4KP6dSCQMSTcRERE5ky0lNKFQSKw6MsOiRYtQUVEh/ps1a5Zp+yIiIiL7WR7QNDc3o7GxUXFZdXV1RtuaeDyOefPmqS5L19jYiN7eXvFfV1eXUcknIiIiB7I8oFm6dCmqqqpQWVmJyspKAEBVVRWam5vh9/szGvnGYjH4/X7VZenKyspQXl4u+0dERETFy/I2NJFIRPa3x+PBrl27ZO1jYrGY2ODX7/fD5/PB5/NlXUZERESlzdZxaJSEQiE0NTWhpqYGkUgE7e3tmpY5xcnBEZxV5rjDSkREVNQ8glD8w8MlEglUVFSgt7fX0OqnnpNDmHO7fGC/b3+kGjd96hLD9kFERFSq9Ny/bZ/6oNjsPnbS7iQQERGVHAY0Bnv+jUN2J4GIiKjkMKAhIiIi12NAQ0RERK7HgIaIiIhcjwFNATweu1NAREREAAMaIiIiKgIMaIiIiMj1GNAQERGR6zGgISIiItdjQENERESux4CGiIiIXI8BDREREbkeAxoiIiJyPQY0RERE5HoMaIiIiMj1GNAQERGR6zGgISIiItdjQFMAQbA7BURERAQwoCEiIqIiwICGiIiIXI8BTQE8HrtTQERERAADGiIiIioCDGiIiIjI9RjQEBERkesxoCEiIiLXY0BDRERErseAhoiIiFyPAQ0RERG5HgMaIiIicj0GNEREROR6DGiIiIjI9RjQEBERkesxoCEiIiLXY0BDRERErseAhoiIiFyPAQ0RERG5HgMaE4wmBbuTQEREVFIY0BTAA4/i+0mBAQ0REZGVGNAQERGR6zGgMcFDa/banQQiIqKSwoDGBD/9+xt2J4GIiKikMKAhIiIi12NAQ0RERK7HgIaIiIhcL6+A5vHHH8eGDRsAAJ2dnVixYoWRaSIiIiLSRXdA8+1vfxvXXXcdwuEwAGDOnDno6enBkiVLDE+c0wngeDNEREROoDugicVi6O7uhiAZPO5LX/oSFi5caGjCiIiIiLTSHdAEg0EAgMczPkpuKZbOEBERkXNM0ruC3+/HTTfdhF27dmHJkiV49NFHEQ6H0dzcbEb6iIiIiHLSHdBcffXV8Pl8WLZsGdavXw+/34+mpibMmTPHjPQRERER5ZRXL6eqqirceOONuPfee7F48WLs2rVLV0+njo4O1NTUwOPxoK6uTrYsFouhoaEBra2tGe1y1JYRERFR6dJdQnPNNdfI/u7u7kZHRwcCgQA+/vGP51w/Ho8jHA4jEokgHo+jqqoKra2tqK+vBzDWRqetrQ1+vx/hcBjBYBChUCjnMiIiIipdugMaQRAySlVCoRA+8YlPaN7GggULAABerxeBQADTp08HAITDYXR3d8Pv9wMAAoEAgsEgYrGY2LtKaZnP59P7NYiIiKiI6A5oWlpaUFVVJXvv+uuvx/z583HdddflXN/r9Yqv4/E4pk+fjtraWgBjVVFz586Vfd7n8yEcDiMej2ddlirdsZoHntwfIiIiItPpDmg8Hg92794te6+jo0McaE+rZcuWie1gUqUs0WhUFvAAYwFQNBpFPB7Puizd4OAgBgcHxb8TiYSutBEREZG76A5ofD4fPB6PbGC9yspKLF68WNd2amtr4fP5UFdXh4aGBkPbwixatAi33XabYdsjIiIiZ9Pdy6mlpQWjo6NIJpPiv+PHj+P666/XvXO/34+WlhasX78eAFBdXY14PC77TDwex7x581SXpWtsbERvb6/4r6urS3faiIiIyD10BzTZApf0aiit5s6dKzbq9fv9iMVisuWxWAx+v191WbqysjKUl5fL/hEREVHx0lTl1NnZiUcffVT1M+FwGOvWrcu5rXg8ju7ubjGICYfDaGxsBDDWcwkYb1MTDofh9/vh8/nEzystIyIiotKmKaDxer3i+C/ZKDXOVRKLxVBXVyd2u0513U4JhUJoampCTU0NIpEI2tvbNS0jIiKi0uURpK17VXR2dqpOb5BruZ0SiQQqKirQ29traPVTb/8w3v/zFxSX7V78GcP2Q0REVIr03L81t6FJD1YSiYTsn95eTkRERERG0d0o+I477sCECRNQWVmJyspKeL1eVFZWZjTYJSIiIrKK7nFootEoenp6sG7dOuzatQvXX389YrEYNmzYYELyiIiIiHLTXUITDAZRUVGBQCAgjg7s8/mwaNEiwxNHREREpIXuEppYLIYZM2YgEolg4cKFuOiii+DxcE4jIiIiso/ugObGG29EbW0tZs+ejdmzZ+OFF15Ae3s7rr32WjPSR0RERJST7oBmw4YNuOKKK8S/pYPeEREREdlBdxua6667Do2NjVixYoUZ6SEiIiLSTXcJTXt7OyoqKtDZ2Yk77rgDHo8HgUBAVmpDREREZCXdJTQVFRUAxgba8/v9WLt2Lfx+P2644QbDE+d4bAtNRETkCLpLaFITSba0tMDj8aC+vh7RaBRVVVWGJ46IiIhIC90BTVNTE+rq6tDW1oarr77ajDQRERER6aI7oGlra8OXvvQlM9LiPpqm9SQiIiKz6W5Dw2CGiIiInEZ3QENERETkNAxoiIiIyPUY0BAREZHr6Q5oVqxYgccffxwAkEgkcMMNN+Caa67Bhg0bjE4bERERkSa6A5rFixcjEAgAAK6++mqsX78eCxYswNKlSw1PHBEREZEWurtt19XVoby8HPfddx8ikQhisRhmz56N3t5eM9JHRERElJPuEppoNIprr70WDQ0NaG1txezZs9HZ2YmWlhYz0kdERESUk+4SmsWLF6OzsxP33XcfKioqkEgk0NPTgwULFpiRPiIiIqKc8moUvGvXLjGYWbhwIZqamjBjxgwz0kdERESUExsFExERkeuxUTARERG5XkGNgltaWtgomIiIiGxXcKPg3t5edHd3s1EwERER2UZ3QAMAc+bMweOPP45YLAa/34+rr77a6HQRERERaaY7oNm1axdqamoAAD6fD4888gh6e3sRiURQXl5ueAKJiIiIctHdhmbhwoVoa2tDd3c31q9fj/Xr12PdunVobW01I31EREREOekOaILBYEYVk9frhdfrNSpNRERERLroDmji8XjGexs2bEAoFDIiPUXjYO8pu5NARERUMnS3oQkEApg+fTrmzZsHAIjFYojFYohEIoYnzs1++eybuOsrfruTQUREVBJ0l9DMmTMHsVgMgUAAVVVV+OpXv4qenh5cccUVJiTPvQaGk3YngYiIqGTk1W3b6/XixhtvBDDW6+m6665DIpHA888/b2jiiIiIiLTQXUKTrqqqCo8++ih27txpRHqKRvjNw3YngYiIqGQUHNCkpCasJCIiIrKaYQENu20TERGRXTQFNEuWLMn5GY/HU3BiiIiIiPKhqVFwfX19ztm0Ozo6sGjRIkMSRURERKSHpoDG6/WiqqpK9TPRaNSQBLmJAMHuJBARERE0BjRtbW05Z9Rub283JEHFZM/xk7hwxll2J4OIiKjoaWpDkyuY0fqZUvORO1banQQiIqKSYFgvJyIiIiK7MKAhIiIi12NAQ0RERK7HgIaIiIhcjwENERERuR4DGiIiInI9BjQmG01y8D0iIiKzMaAx2bJIl91JICIiKnoMaEy2t7vf7iQQURE6MTiCzft6IQgsBSYCbApowuEwqqur4fF4UFdXJ1sWi8XQ0NCA1tZWLFy4UPMyIqJS8unfvYLP3bUKL2w9bHdSiBzB8oAmHo+jra0NoVAIkUgE4XAYDQ0N4vJgMIiGhgbU19cjGAwiGAxqWkZEVEpSpb/PbDpoc0qInEHT5JRGCofDaGlpEf9ubGzE0qVLxWXd3d3w+/0AgEAggGAwiFgshlgslnWZz+ez+mto5oHH7iQQEREVPctLaGpra2V/e71eMSDp6OjA3LlzZct9Ph/C4bDqsnSDg4NIJBKyf0REVJjBkVGcHByxOxlEimxvFBwKhcQqp2g0Cq/XK1vu9XoRjUZVl6VbtGgRKioqxH+zZs0yK/lERCXjg4tW4LKfLmdQQ45ka0ATi8Uwffp0BAIBQ7fb2NiI3t5e8V9Xl31dpz2scSKiItF9cggAsO1Qn80pIcpkeRsaqaamJll7murqasRiMdln4vE45s2bJ7ajUVqWrqysDGVlZeYkWif2qCQiIjKfbSU0Sl2v/X5/RtASi8Xg9/tVlxEREVFpsyWgWbZsGebOnSs2Bo7FYgiHw2LVUypwCYfD8Pv98Pl8qsucjFVORFR8WPRMzmNLt+30wfQAiKNdhkIhNDU1oaamBpFIBO3t7eJn1JYREZUiPjMRjbE8oAkEAqpDdft8Plm7Gq3LiIjIKgyjyHls77ZNRERuwyonch4GNCbjcwwREZH5GNCYjM8xRETkNIIgoH+ouAZIZEBDRERFZ2Q0icbHN+GJzn12J8WRvvXX9bj01uXoOj3JaTFgQGMyVjkREVnv6U0H8PDaLvzn0o12J8WRVmw7AgBoixRPwMeApgAcBZiIzNDbP4wjfQOm72d4NGn6Puxy/MSQ3Ukw3ODIKDZ0xZFM8uajhAENEZHDvP/nL+DKX7ajb2A452fzHbzzhTcO4V3//RyWrtub3wbIct9/qBNfuHs17nkpc1JmYkBjPg4VTER52nM8d/uGfEuK6++PAAAWPrZZ97osnbbHC1sPAwD+uGqXzSlxJgY0RERkqxETqr48fJgsOQxoiIhcZsv+XvG1HfdtI/e5+LltuPiW57HjcJ9xGwVUR6Q3yvI3DuFTv3vF8LRTfhjQEBG5zGf/sEp8bUf1j5H7vPelKEaTAn69fLtxG7VIw/0RvHkwge8/1Gl3UggMaIiIqAhZWeV0YtDaAepYmaaMAY0LrdvdjZ8+tcXyi4iInIdNRaggRdTC2/LZtkuNGXlN3b2vAQAmTpiAWz93qQl7ICKyltGBmZVxnhXtdWT7s3Rv7sESGhfbdeyE3UkgF+jq7sf//dNavLrzmN1JIZ1KqfTF6JiAN32NiugkY0BDVOT+c+kGvLTjKL6yZI3dSSGdiqg2oKixi7gzMKAxmZnnOS8i0uJQwvwh9M3w1Ib9WLn9iN3JIIu4ucrJasX83QrBNjRE5Dj7evrxg0c2AAB2L/6MvYmxEZ9Z3MHqNjSGcnPa07CExmSFnitH+gbw6+Xbsa/H/VO8nxwcwfce6sA/Nh+0OyklxY351bEinFiQiMzFgMbhvvNAB+56cSe+fN/rdielYC0vx/DMpoP4zoMddieFyLGkT/tuDEbJZYqoGJABjckKPVfW7+kBAHR1nzIgNfY62jdodxKIio4dtyPGWXKl2J7x2IlBLF23F/1DzhkPjW1oXKz0LiEqFa5uk2CgUrpPelyco7n6fM0z7f+n9XXsPHICHXviaKq93OBE5YclNCbbeYRjxRhh26EEft/+Fk4NjdqdFHK4wRF3nyNuvjc6SSkFg3ZI3duWbz1kc0rGMaAx2TOb2ADWCJ/87Su4M7QDvw3vsDsp5GB7j/fj4pufx389utHupJDNGBhqVESRHwMastB4DhM7ml/J1eb9vUYlhhws33vRH1fFAACPdewzLjFEDuOkGMRJgSMDGhdz0kmtF3s6WWd/3P0NykuJg+4Prubm/JHyw4CGbHHsRH49nphJkRoGA0Q6FVjE4qQ8mQGNqznoTLKIm3tCkHZOKsYmIndgQEOmOjk4gnW7u5FM8g5F5iuGcNfVXYAL4KQn/ZJSRAee49CQqa5teQ1vHEjgF194r+n7GhpJ4ov3rMZl51c4ZlwEslZphgJEBLCExlZH+wbxwOt70DcwbHdSTPPGgQQAa3qdrNp5FFv2J7B0fZfp+yKzMTQBtFWxWjVKLadkKFJF9GOyhMZGX//jGmw71IfXY8dx11f8difHVEZluWp5dzJp0E6KmCAIrhim/WDvQF7rOf+b5ab39lKqVVS5FMO54AZOOv1YQmOjbYf6AAAvvHE4r/VdcF8SZd5EXZT4IhI5PTeY033voc681nNQ3moIoei+ERmD+acSBjQFYFZTCOOPXjH+HruOnTS0SnJo1H3FWCyBUGdHiZsZu5Ruc8v+Xqzeecz4nVCmAn9MJz1YM6AhSxhX5eSgq8dkOw734WO/XomrftVud1JcoxjODmn85tRhCsyOMT/7h1X46pI12NfTb+6OXItBvhIGNE7gzDzLUCUUhxjmpe1HAQD9Bk7I6dQbpFGYzZvHjoKyfT0c5dp0RVQCyoDGxdx9a3J36sk6RZTfEpGJGNDYpH9oxO4kWCqzZCC/uxTDICp2bAhsDCurp63/xZgTKmFAY5Nv/WV9wdtwVTWOm9JKRJZTqg4tpHSOjck1KvBG4qTDzIDGJq/FjtudBEtlXjL5XUSuCuLIEA7KL0tCV3c//rx6l+WlyPmWTHV196O3397BSXNlS72nhvG313bnPSmvqZwUkRSIAY0D5HuPXv7GYcSOnjA0LVTcHlm31+4kUA52318+/btXcNvTW9H8/HbZ+9JkWVX6kesB5nBiAB9ufhHv//kLCus65+nnvx7diFufegP/78/r7E6K4Rx0mBnQuN2P2zbanQRNPJ70jNqEcWjsvhMYzIy2FE9tOGD4Ns1WbL+r0Yy+n/QNjpXMWD0OTD498DZ0xY1PSB5ynaHhN8cGT928v9f8xFjMSZcnAxqXM7JLr5mM6i7soIcBIkdw0P3EcGt3dee9rrTk4EjfAJqe34a9xzmuTQYnFbEUiAEN2cTdF9Gj67rw/Yc7MTRi3si7xT5mDLmXVdU5d4Z25L2utOTg+w914p6VUdTe+6oBqSIpJ8VDDGgcoJATopCMpfvkEJ7ZdACDI+aX8hh10julXnzBY5vw9MYDWBYxfxbxUlfMJRBGsOOKcEo1oNZkrN09VtJzpM+BjXLt5pDf0ggMaEpY3b2v4nsPdeJ34bfsTopmWjNvqzLc3lP29q4gMotDnh1yyH6dS9NfRPdsAM76bZx0bBnQuFwh53X06EkAwD82HzQmMQ7y8lvWNGg0M2PhAGulyYobRD4Bv+kPCQ66SZM7MaBxOSdF6mqsTmf0iDXd2V1y+F3NSU+AVnPL9W2IPH7nUj03DP3enG2bjFQKjT+t/o5WXWRa9vPA63vQcP963W2VSuG8oExWlMyVaiBACgo8GZx0LjGgcYBCMjAjbty7bejKmG+6ta7npFDg5ie3YPkbh9mAmDSR3iCc9PQ7aGKPPgDiReuUBsdO5qTzwkkY0BAA4HWTp2JIvwDzz7OyX8l2ZIN6SlHiNg/P7lZsS+QM334gIr428xfRkzfwzLCfk4IrWwKaZcuWoaamBvF4XPZ+LBZDQ0MDWltbsXDhQs3L3K6QqgU96yaTQtannz3HT+adBieaMMGaq0zPxXzH8u25PyTBG3lpsuJXz2cfr5jc0D6fK1Yt+LHyPntiwNp5r0iZLQFNIBBAR0dHxvvBYBANDQ2or69HMBhEMBjUtMzp1u3Of7RLoySTAj77h1X4wt2rNRfpDo0k8Wr0mCXj1BjNQQ8NRaP31DDuWRlFV7e1VZROqYH4TWgHfvhIp6VVIk5tR2VGqoS0/90kNV2EK3G27cJ4vd6M98LhMLq7u+H3+wGMBT3hcBixWEx1mRt8bckau5OAI32D2HowgY37ehUvPqWM82dPv4Gv3LcGNz22ueD9pw+I56RiStLmlie3oOn5bfjC3avtTootftf+Fp7ccAAde+Om7seKgEnLPuwKpvR8/1ItxTT0l3FSRFIgx7Sh6ejowNy5c2Xv+Xw+hMNh1WVuYGZjOq2BQa4LX2n5Q2vGZmZ+onO/7nSlS09mvteQ5kBIwwdHk4VfyE4ZudgKqckKj58csjkl9jK7xFL3WWnDKWjGLbB0rqTCOSkEcVIW6JiAJhqNZpTceL1eRKNR1WVKBgcHkUgkZP+czOoTwq7zz4gHAc3xTI7lD7y+B5fc8hxeixbWGNrMY+nU6oZ8CILgyqpLu2nKG5x0dzNAkX2douekAh7HBDRGWrRoESoqKsR/s2bNsjtJptE+FUCu7Zh780zPmO2O6m9+cguGRwX8xyOd9ibERQrJt364dAMuvvl5HIifMiw9SqzIXM2+ViwZKdj8XeRNVy8nJ38Rt7A7MzaQYwKa6urqjF5P8Xgc8+bNU12mpLGxEb29veK/rq4uk1KtjdPOFzuqSYzao+ZxaCwar8Zpv61TPbXhAADgwTV7bE5JEbLhHHTFaV/EF6eT2tA46TA7JqDx+/0ZjXxjsRj8fr/qMiVlZWUoLy+X/bOTE35vpz3ImD8tjLajXujFaOZv67QGj0Y0Vs2ndEPPbq3IXE3fhyVzOZm/j3zpOe9VP+nkL1lEnHSYbQloUqUt3d3j3ZkDgQAAiIFLOByG3++Hz+dTXeYGudqeFpQ/5pG7Kq5hciZtRalQPiOsFlp9UEqNgt3Amion65TS2ZW6lvRVOTnobppFtwmN6JntKJtk9Q7j8ThaW1sBjA2wV19fLzb4DYVCaGpqQk1NDSKRCNrb28X11JZRbnZf+OnXX95TH2gteclv845ytG/Q7iTIOP/WURykJRRm3bi0lIKcGs7eiNsVgbxD0th90vjr2IgemsXI8oDG6/ViwYIFWLBgQcYyn8+HlpYWxfXUltnF7iABMPDGbf9XMZTRbW3MWl/Nfa/sMm/jebDrdNdXBeH+E9kB2QoAYK/FAyiSdsdOqJf67I+fwshoEhfOOEtx+YAkWO3uL6wEySFxIwAbAhqyh92ZpFEnvdFVSQU3Ci5wfTfpPeX8uaiseHB1RemEycw8BHbnVW6XTAr40OIVAIAtt12Ds8syb/PSEp7hEc62TS6meP6Znkc78yZQ8M2JNzdd8jlcTsowrSD/uuacX4UeU1ec9aV24pw2Kvneh3oHcn5+QhFFAUX0VdyrkJsq76dZ8LiUJLPuYU6oXi4VuqoYVT7qnGYm1mZG0mOS7byV3jcKfahz0j2IAU0JsiNztr7KydjtFbofGpPP8RpQaZyazqxzO58edPnvS993MGugvytnTzdlu7no6uWkEvwkSzQIlR6T0SzHQPr2hAJPHycdZgY0LmfYgHUGbceu7edrX09hI9c66emkWP31Ne2D8allrqNJAd/6yzrc+cJ23WmwMs/Wuy+zGkJPmZT99mDGeW/0Jp1TQmMteQlN7s9PKPDHdFLbOgY0JUJ2ktuXDFG+T9LaB8yzJtJw43xLR/py16ubJZ9fPa6jF4bazf2lHUfQvu0Ifr9ip+40SM9XS8ehsfH0Ut+3eQkzKn+ysiS6TCX4s5OTSk+s4MxfocQUkjV0FVjCYJX0zDFXt8PsG1JbaM9Nx21e3VnYhJx6SSelLLRELBe1DHxwWH3We7UboKUlNDp3Ztboy3b15tITiKh91Mqb+XvOzz4avdWHsdSCGCkGNC6ndfA16ZOrHSe8FSUZVrZzsHo/bib9XfJp16CvTUV+y777YAeCv3k564zgpXiTKLRthd2ytR8pdrK8PstZL3230ConJ2FAQ5bweMwf9Ey6dcsCGmt242pW5pf53sOe3XwQO4+cwJpYt+JyK0bvVdqXab22NFyLal/T1HFo0v9WKzlT7eVkXUCjdjysjqtKNI4DwICmZMhO8iI94aUZ2LZDfZbss4gebopCoUFztt/T0puEQ65Pq5/cU7tLP9b5HnsrfzO1I2V1r1LZg12JPXIxoCFLGNZtW2WZNN9oeSmW/YOkm56u0+mszM8LbVNRTMXvagptQ2PqUUpLm1rVkWoVo0OKKqzubSX93lmrnBxybIzGgMYJNOYOB3vzb1ApL6DJPJnNbgBo1JOCWjrtGHfCjcPg9+Qxd8vQqHqD2mInP7XM/c2dcqtRO7XNOO+zXb75TsRoZSChdjysnl8sqeFStaN63goMaFzklbeO2Z0ESuPGvOC2p7fqXsfOBzp9I8dm/2z26qTxdX6dZYwa+ya9tO/AW90oOLU/o461pW1o1NJh8bPAYx37xNfZDoGsA4UrczFlDGhcZGIBobSsGNKOPFIh6bGjJ9A3YNygTLb03iqmxxuTWPm7qD2VaykB6Nwb17WuGazYl5ZdWN+GZmx/etrQqAWw1pbQZF9mdcnxklf0VbcXUxbGgMZF3DyJmNI18/H/eQn/3PSiYfso1aHOnc7K0o189nT8ZO4qOCuL6O0rDZJTrXKycH9qx8MNbWisTsYBDRNSOuQUM5yLb5HFQ2vmUMgT0+DIeLmnk85lvcNmqxbt2jK+Toko4NjqHYpdbf3cn9W/g41dcVO262Ravo96uxDjpao+Mrtt57c9a6ucnNO274zJE3N+RjYMgZmJsRgDGheZWECl9nObD6ouN30uJ4Mea51UtAsUV3GtGqNKDaZO1p/l6AlU1QfWyz3IWD7bNZreANCsc9CuHl/pwZbqIVAdh8aQ5GijMV+65LxppiflC3MuEF9rakNTRHkYAxoXKaiERtJLRenpbNJEs3s5mW9klAGNWQq5OUhXnZvHDM6de3vy25nWVTREDfJGlKXB6u+Z7Xkt39IxpzQKlqbionPPNjsp0PvLFVM7QAY0LlJICU3NOytN27aV1FI5lGXYejPlyjOLpaqikO8hXTefoFzPrvuHRszZvpWNgh2yD7UswYzzWhxYL31f+W7QIZee5QPraRmHxqrEWIwBjQNojZCVejl9/JJzNa1bccZk8bXSyWx21z2jHgKe3HAg6zKrxkqRZhiPd+xX/awd7XrMYFQJTT70nDsvbj+qe/vnlpfl/Iz0ad/sJ1qnBMFWP7mLbWj09HJSObvyHb8mH+pV4eOvLQlWNVRZOuUcMxoDGgfQenIplaK8XUNmDOSeqM3snhVGZo3Zjleu2ZSN2//461U71ccGKpaMw87vMWWSudmUNNjPRtbLybykqO7X0O3a2DZH7/7yn8upwATpoNoo2OKnGmlenq3aTfru9LOmmJwi6zCgcZEJBVQLSQd3UjrH3XTfzfbkVW1J/bS+m4yLDquqgkpoZE+M+jc0s/KM/HeugZYkWRnQOeVatG0cmrSrJu+5nCy8+rSW0FiRJNn1puHzs2ecqXsfp4asr97XggGNA2gt2lWOZ7StO5JjuEotXVcLYWTxdbZqpykTrTmd9dzcnHJzKlRBN4cCj4FRxzBr8buWdY1JgnNoKaEpbHXdxCwivcopz3Q45dqzunQzqeEBotChFPQOt2EVBjQOUMjJoTVOyNXif8mqXVmXvW2atmotNUY+693/2m7F963q1aBnL8Uy2J+dbYFqLlRv0F4obSU0469jx06YlxgHsbyEJsv7RvZyOteAvEyJ9jY05l9I0n1kD+KLI19Kx4DGRZRuKlqzHGl7WbtOZqPu7dnaA1n1rYokRtGlkHYAhZ5v55ZPLWj9lHxGolX6zMNrugxJT9Z96TxcZoUdVo9MbnQvJ6WA5mKTxoFRa0Pz8Nq9puwzG+nwFVkv2yLNwxjQWMSIYsdCtjGqUOV0VZX+MUHy5jHuKT9bZybp8SmfOknxMy/tOIrZNz1b0P71TZZY0K4co5DvUegx0HPeX3ZBedZl2Uoc9HbbXru7W/Eje4/3464VbxlaHK+p9Cif7WpaS2WkYBPO69Tvo28up+zLFB8ATSp1Utvss5JBTa3ID6TNC8yq7nLq0DUMaCyS73k1V1LcrrQNrSeWLAg4vR2zB9OT8sCjGFTlI1tpgfT4zJ83S/Ez//dPawvev66h+A16FLK7t5T0e+gNhK1Mudp4StJF0uOppVpQy3f47B9ewa9f2IFbn9qi4dNq+3JGFGz10FRZq5zyPB5K14xD78OGmjNLcs/I8hlnnGHGY0BTACt6u7zr7eNFpEoZr9bxY5SqabTeI43KBEYMKqLJVuUk3XwhPcKMZFSplJHxzLQy5dIrNdLvsWaXcgmFWfR8d/XgZPyc0NsocsW2Izk/kxgYG9RvTcza45PPqa7lOzull5Na5qkW7Cg9P9ldsmDFc4n3zPFhCLJ229bZEyoXux+4UhjQWMSYKqfM9zQ3Cpbckew49TweYNigge+yldBIL14zr6+DWmazFdMhT8jJQf0j2QLGNi7++Hu0DcZo1P7zOfenSaoM9TyhqxUCSq8Vvd/nkI7fvNCbpt7DZVbgob5Z4y8wsQ2Nnl5OqlVO1pXQOGn6ANnXtqhRsEPiGQY0VimkSWVKIReoUumIlSehB8CwQXMtZSvpkb5r5mBWPf1D4utvfPBC1c+mp0I667keRn6dfLZVUBuaLK/VXD6zIq99qwUqHtnnJGnS0k5F8iFp2pQYGWBYXf1U6DQVZsj33FM6z00L/jR+zupeTmZlg3qCTisxoLGIEcGD0smpdbOyEhqdaTEqDzCqhCbbwHrydhGG7ErRZEn3j1xj36Qf63wPpZEZYT6lLYYVKZscTKl9VvoULSvN05AoaTVn8D1v156gPOg9RLuOnTRsH3Y+aYuNgtPe13ruZ8zSrfQA6IwYLS9aH9Lk1Um5q5zySouGY20HBjQWMeaGlP82FNvQaNye0hxSenk8+ZdOpNNSL2zm+C/SOuryXMPmG/QkY+TXySfzMWqk4HzW0bO61hIavW1o9MzHU3iVk74DNnXyRN37yHacpO/bNQ5N+vdXO/fUjpTyd7Sjem5cIdex1jaIspLqrFVOktd5pCkjoNG/CVMwoLFIvieydIhpxRKaLNvtHxrBziN94t+jsjY0mSt95ap3Zk2DEQ1sPfBgyOSARt6GxrxLTJqx5Aqc0pfnGrFZ63YKkU8SCmpDA/VzT3EdWcChfd9qn5SOq3I4Md4mRsvW9QTLVgcCl6p0Vc8m+zU0/lp9tm3du8wpn7mc1Ch3285rUzlZ8YtrvQa15INqx3Tzvl78cdUu1RKh9NWdMoAoAxqL6P29k0kBe46flA3zr3TSZLtBfPp3ryBw58t4LXocgHI1jXRzXpWSBrWusHoYV+Wk/L5Vs9qOygIa9c+mL86357qxbWjyqXIqYIc6S0NUVs9JvYRm/Dz+5T/elKQp9x70VGcWXEIj229h28om23kon1XcnH1nI/ZySi/VVDsGKh0BrLzFam0UXEiatM4erqX0Ue2Yfu6uVbj9ma14rGOfpn3k2p6VGNBYRG+V081PbcFH7lgp38bpTZw1ZbyIecpE5eLm3cf7AQDPbBoLiEYV2tBIUyRt6JrOqConw3o5aXjqMPOJIaklxxAXy5fnmvVc0z4LlE9wZNT+tW5Fdr3o2LV6G5rx18dPDCpu/uK3K48kK79+MncyIjm3Tw5aO3FfPlenlmpb67tt619Hb5WTQ0ZzyIvWvEMWEGc5Qlqu5+2H+rIuc0qJTDoGNBbR+/s/tCZzuOzUSXTGlPEurVoHx1Ms3ZG89/Da7MO5G1dCY8xF8A6v8uzL8moBQ3alqLASmvwSZncbGsN6OWncjpaGjUpUS2hkjYLH3x/VUIWYlJ1bmZ+RntuJAkcK1nuszzCpDY1aqYMZl1e2MbU0nzMZ62WuaFReli7bVtOv90KuI+m2Lj0/ezWj9Htn25/W0p6s+8jYZ0GbMwwDGouo/d7BS7X1mhBLVvI4e0ZkbWjGaD2njcgEPJ78emMoyXa85JOymXeFabkBZlueb0Zi5PfJp5Qo37Y/QP7BidL6uWhuFHz6/13HTqLu3tcy3k93gXd8Pinl3oaSNwu+XPQdo7waBTuyymns/8yqozxLNY0pEFa0/VAfPty8Qvw727F6csN+w/YpzcPVfhstD3Z6e/mpra/0t10Y0FhEVh2SdpadrXHk1tSJl63R1yNr9+I7D0YwOJJZ5K10I9V6Eto9HkVmd0zlz8meonVkZnqDBXlmkGvj8j/zr3LKazXDtvWUpC1XIfJ52taT3FGNpYCp3/yO5dsU35dqfTmKjft6xb+Vrhvp9WXk1WLWfSL05mHF97U2CjaD2MsJ2q53QL3E08yb7G1Pv4Gu7lOSd5QP1raMapv806S927a+Esds1IOmtN9IU8rMp38MdMqL9AdP736nufV6MvV55eU3Pb4ZAPDB6szGXEmFNgBWltCoZfP9QyM4c0r2UzE9GDO623ZSAPRMa9Uv63mmvp/0pa/HjqP6bWfn3MfA8CgqzpgsTnRoZOacT2nP7uP5l64dPzmY+0PppKU6OpJ7QmUkZqWqr8zeGkD7m4dx2QUVOK9iKmJHT+BX/5AHPUo3FmkAXegDQK7va0Rp3d4sv6fawHozK8/Avp5Tpz9XcBIyZJ08VGWdUdl5IkCaz+jpFarXySFt7aSMfBiUPgypBnmyBzvlDxZS5fTc5oP4n9AO2Xsch6YESNt6nBgYwaZ9cQiCkHFzOhA/lb6qotR6uXpcpNfh954axm/C4ydgqr5f60loSLdtlU1s2BtXXTf9O2ZLdzLHcclGy8Ud3noYs296Fg+v3Yu/vbZbkhb19dKXR3b3aNrXJbc8L5u12dhGwfq3VVszM+/9He1TboCrlZ4i8dR8SorbUXhyTT8Uu46dxLf+uh4fueNFAFCcOVvpdJHebE4N59couGNvDx5aszdnWzMjqmSyrSH9btJLtqu7H9Om5hhzqUBZq5xUzlf1rsXm3WTTs7NU2p/bfBDffagDiYGx8yZ93M1CkiTNp9Q6WMg+Z0JAc8ODHdh55ITsPWeEMwxoTHWlZFbiL9y9Gv9612pUNf4DL+84Kvvcut09WPXWsZzbS5000otCuTu2vK71p09tkWVUH/v1SuyPn9J8cRkxKffrseNZl3XsVb/JZ9bXKn9O1hjOoIakKdf9bT0AoPHxzbJANVemmb7t96g05kv5z6UbMt8sIMf48pVjYwzNOGvKWJp0VMcd7D2FJa/EMDA8vpK0l50Wby8fb3+i9aSTt4caf/9wYgDrd+c3+aN0z28cSGTsR0ptEMj037R/aAQvpk1e2T+kb86unpND+OL/voqfPLEZd4a2q342W7WlnnGetDQKTt2lw1sP48PNL+LNgwnN29dKlled/j+9mibbGTMwPIq/Sh4u0hld5fTc5oP49O9eQfToiYxlk04/9N3wYAee3XQQj64b62SR3kO0kBRJr9u3jmSmIeUvr+4WX49mudiNnvdOMLG9kh4MaEwkPZePSJ5S6++PZHz2a39co9izSWq8qmj8DEwFNNInyeMn5V2w1ymUCtz3ckzzBT80mpR1S/19+1v47yc2Z72ZDwyP4mtL1qD15aj4XuzoScy9sFLx879+YYfi+ynpXcqzVjlJX+u4SPXOAu5/5/j3UFp1Q1dcHJgqffFF5+aublJSWBuasZXPObvs9La0b2x+y+v4xbNvovHxTXmnRT6oozbyhsTjrvpVO2rvfQ2RPdbMaB3Zk3ntpB++7z/Uif9q26j6mVz2S0ppw2+OB0dKAZfS73cgfgrv/elyLFy2KWOZkslZpuxQ2vafX92laZv5kO3udIa5Li1gzZbP/K79LbEKDFDoeZNrfzkc6RvA4ue2Yc/p6rkbHuzA1oMJ/OjRjRklzukB8LETQ+jq7kdbJPtYLnppbZgvHb08W0FOob2c0lk951g2DGhMpLf+9CdPbJYFAelS56Csy2kqyJH2vNEwb9PQaFLzjWnL/gQ+8duXxb/vDO3Ag2v2YsfhE1j11jHsOCx/ompb34VVO49ltD04e2p+Tbbuf22P7O+sLfdz9D7q6u5XXE/vxS0txlVqgP2Fu1fj9me24u8bD2RkxnqDp5RcQcgLbxzCv961SvHpMfX9Jk9SHrhMzd7Tx0xaDaI18zrYewpH+gYKfxpUWGnVW9lL/LJvJ/OtXNNxVCsEoOm/RXta6Qww9jtvO5SQPQgYJf2+JghjT+VDo0ksXZ99+AWpWZVniq//qXqGbFspB+PZ28vkKpmM9w/h+w93YuX2zGMjJetVpZCGbPsHgFfeOqq84LRCb9o/eHgD7n0pilpJLzgA6FOohlyRdg54PMDVd76Eg2mztBdSDab1QeS9kpGjs1XJSd++Z2VUrCLLl0Oa0DCgMVM+A9L96h/b8FSWrn6pk0ZWQqOhV4dSMiZN8MguLun8REpiR8eeUv6x+aD43rZDCXztj2vwid+8LPtstgZz+WYw6T1ssg7nLXmttKuN++KK6+kdG0Z6k3rg9b1Z07TjcF/Ghf6/K3eKrwVBwLLIPmw7lLsoP1dmVn9/BJv29eJHCtVVqSAqNZFmUhCweucxPL/lUM79Kqcl92dODo7gg4tW4MpftsuHDMjxPTZ2xXHLk1sQl9w0lNZQelpd8kpMns70MUAUttSn0uYGAMoUSjK03FjuezmGT/72FTSebqifi54bQq5eVtmMjCZR/7f1+ORvX8bPn9kqvi9t9C/dttbShW2HEvjIHS/iyc7xfKvp+W14euMBfPPP61TXlaZ6fHLK9N9NWXqsGO+X35QVA7G0rT2z6QA27+vFaFLAq9Fjskbla3aNBc3SNmBaPdm537CpXlK0xsbS6y1b9aT0d956MIFbn9xSUNocEs8woDHTWRq7Y6dreSmm+H5SEPDmwYTsqXLp+i58/Y9rcOvf3xDfk3YxBZQDmgkej6yu2nfOWfJ9Zckgv/Ngh/haOq7M6p3H8MDreyAIQtbMOd+RgvenNZrOd/CzbJl+rq7U6eull7I8u+kgrvxVO1ZuP4K7X9wJNZ2SBtAvbD2MH7dtxCd/+4rqOoD2G15c4ekxlf5JkoDmq0vW4NsPRHCwd/zYvrjtCGbf9Cxe3anenkvLU6Z0uyOy0h3gzhe2w9f4LO5ZGc3I9D9/92rc//oeWaNDQQAO9Q5g+RvjAdhIUkD3ySFc/7f1CG0d64L8i2fflG0r/XfN5ylS6ZTREtDddfo8aIvsk83Hlk4QBNz61BZZuwep5zYfwvcf7sRJyY1W67ktCILsOl65/She2HpYoSvxOOXvq/6Ff/jIBuw53o8fLt0gloLKqoIEAY2Pb8ZXl7yu2mMx2/Nf38AI/rRqF773UId8DKi0baVXTSsFsMvfOIyB4VH8evl2/GX1LnzvoU587q5V+OOqGL5y3xq896fLJWlTTo+A3F3z00tmpOvmK1v+tWV/L/7Q/hYGTjdGl+azWfO8tPdfUWjDqXU6B4Dj0JSE/7j6orzW6z6pPA2BIAj41O8yb36vvHUMT28cL8WQ9nJ6cM1exZKivWnVL6eG5TcWpaqR9BuZtB7+q0vW4OYnt6g28H09Zky7B02NghUusEkTlE/3j/16JZqe36a4DICYUaSMpJWKffehDhztG8Q3/7wOdywfb9D5vyujir1kUp7dNF7a9efV6u0UUhlG38AwLrv1eTRnSa9SvjKaVkIj/W2P9Y2fa//vL2NP019ZsgZrYsdzFlePJgW8uvOYrLj62IlBXP+39WiXtAORBi3/88IO/H7FTiSFsad4aRVrtioEQRDwgUXtaJC0PZvgGRtDJrT1MK4/3WA72/ce347yttU8vFZhxO6kgL+s3oWbn9yccW4oec+tz+Nbf1mnGNDf/eJO/O21PVnnzbnrxZ14euMB/GnV+Pmh1JRC6Xv8+1/WIfibl8Rq0QGF6tGxdcdfp//miYFh5f0B2Hu8H19bskYWIKVKpKTH/iN3rMTDa/di9c7jWBM7jt7+YSx67k1s2d8rK9VJlRT980XnyPbVubcHP39mK57ZdBChreNB7fa0qu70XC5bk5Ov/3EN7npxJ3729HgpVXr1uBqlkpf3vkPbBKErtx/FwmWb0HNyCH9ZvStrXq8k/Xy+5XSpymf/sAr/E9qBP54+R6T5U9aHvxwPaYC+8ZQcEs8woDHLE9/5J3jPnJLXuocSytH9LU+9ofh+unmzp8v+Ts3rJJWeEb95MCErCVGK7L9w9+qc+97b3V9wA7G9x/vx+btWyaq3pPqHRvHSjqOZgYbs6Q14onMfnugcv1FMnax8uvcNjOCelVEMjoziuw91oPXlqOwGcTJtbJPbntb2OwDIWq3T2z+Mv0uC0NskmauSVHJueXILTg6N4n9XKre1EjBWcvHt+yNYse0wth5IiKVCqWkypBlyqhQjvQfL/NbXs/YgSR2bm5/cjK8sWYMP/qpdXLb4ubEgY9Fz4zeIk5IeP+njxPz6hR1oO93uI1tPP6WxZTzw4EhivCpA6XxNz6SVq66yn6vPbT6IZxXOwUfWdeFnT2/FA6/vzVqamq592xGxhGlgeBQ3PbYJOw735WwQnxJX6cIvQDnIf3H7UUSPnhQnqM120xEgiNWo6Z/ZvK9XsQTzxMAIfty2EavSSvOiR0/ggdf3yEqRpQ9PnV1x3Pr3LWh5KYbP/mEVFj42XiVXNmkCPnLHi/jWX+UB6rsk82updYmflFY9mO1mrtRJQurzd68Wj5mSwZFRbNkvv17UpiJIt3R9F+bcHsLPnt6Kb0uC9IHhUfxp1S787bXdYvA7MprEj5ZuwENr9mZ89/tf3yNrF5gKLKXndPrDV/ToCfz86a1iL7+UVJ4gaxMoiWheix7Hon+8mTWAd0qjYA6sZ5JspQFWmFmpPNeR1KsKF+yHFq/A2p9cjf6hUcw4OzMYS6/KGlQ4uf9z6UYs+OTFOlI75g/tb+Hq97wdSUFA8/Lt2LivF995sAO7F38m47MPr92Lh9fuxbVzZ6K59v0Axrrz3iO5yT//xiE8f/oG8r53eNH8/Db4cgxoF956BM9uOohnNx3ErmMnseiLlwMAbk+rysjVkFRqV9oAZlfOno77Xo7JZntOiR49MTbonsKjUWowvw1dcdX9dXWfgv/2EACI3z8lVaImTX8qEHjgdXnDayCzMXZKUgBODY2K839J20wdVgjGc1Vh3bhsEy67oAL3vaIcHPzl1cx0eDzy8ZGe6MxsdxY7egKXz/SKf0urwYCx0pFNaee01A2S6tVs1LoNp+s/PWll4+Ob8UTnfjyyTlsDXmAsuLrmsvNwZdV0xQBD+t7XlqxB6zdqxL9TpYTZbjmrdx7HZT9djpav12D2DHnVc+LUsGJgcF2WUrGDvQO4WaU9hrQEM13/0Cj2KDx8SXuaSTtaXDHLK7seJp8O2AdHRrH8jcPYvD/7b6tmY1ccX77vddl7P3ikU3w9mhQwlFba1tOfX6PatZIeXf/VtlEstb31qTdw+xfei/Kpk/B453483rkff/7mvIz1n9syHnCvPF1lLBXZ04Mv+Weif3gERxKD+MWzWxUDulTp3cU3Py++l5pba3BkVDweLS8rX6NOKaFhQGMSG+OZjFEc9bhS8rSdy+9XKLcXWblNvfeBkv8J7dCd7kfX78Pnr3gH9vX046+v7slavRO486XTr5SHe0850jd+M354bRc2dPXiH//xz7LqPL2k1UrAWAa2Nss4Kje2bcQHfDMUG6qu2HYYd6/cKStt23G4Dxe97Wx8409rNaVlslIJTVLAY5F9eFBhyICYytxb77n1ednfP1q6AbU1MxWL47UMyPbp32dvR3TsRGajTA/kje5/nNZtGgD+9a7VuPsrfnzqvedhwgSPbADHebMrVW+uWumpMth2qA/x/iHVMZmyOdA7gGtbXkPHLUFsVgjCpEM+rNp5DH+VBIE/eGQDAPVRlAdHkooNeKdNnZz3hKp63Znl+v99+1via2kD5sq0jgzJ5Fjp4Xcf7EQ4y9QOepRPnSQO1CjtmKBUGphqx1WI9Lzilie34MefeLf4t9LvJ60q61NY/uzmg3jzYEL1WgaUAxKPZ+x4zvl5KFfSGdAUOztLaOyW7Yadj/QnjnRfXbLGsH2lV/u8eTCB25/JLEkxS8feODqyjJqsVDXxid+8jC/OeUdGsX82qRIaadXitS2vZfu4LqmnSCVGTUoqdTgxmFECpeS7D3XgB1e/Cx+75FxZ+nJVO5jhT6t34cE1e3SV8KVLlb5J/U2hQXF6m7BUUKPX2VMn4XAij6krTPK9hzpxzWXn4e8bDuDF7fIHp+FkEs9tOWRIMAMA55ZPRWIgcxgEtdGo8/Gle17Fkm/MVVwmve7/lKOdXTa5gpmU+9NKae9ZGcVEj0c21Us2Tqly8ghOmYTBRIlEAhUVFejt7UV5ufa6zlyOnRjE3F+EM97/0EUzcP+/X4UJEzw5b8hEVvm3Oe9QrJohIirURy9+G1q+XoOySfpnf1ej5/7tqmKEWCyGhoYGtLa2YuHChXYnR9Ev/+29ePC6D4j1+yt//FF7E0R0mtaSHCIivVZuPyprg2MHVwU0wWAQDQ0NqK+vRzAYRDAYtDtJMp+/4gJ8ed47Ze/NPucsXFk1HRMnePDzz1+Wsc77Z3ktSh2VunwGCCOiwn34Xefk/hAVzDUBTTgcRnd3N/x+PwAgEAggHA4jFtPWbdJsV1ZNx+/+zxzFmamX1n8A227/JL7xwdl4rfHjePK7H8L/ftWP5T/8F3z/Y+Nj1az9ydU4WzIY32WSIayvueztqvt/z/nl4jxBP/n0Jah+21kZn/lR8N1Y/MX34Z6v+sX3mr90OSI3B/C591+g/ctqlK23008+fQkA4IKKqYrLs3ngW1cVnCYiM33mfefbnQRyoPnzZtmdhJLgmkbBHR0dmDtX3nDK5/MhHA6jvr7eplSNmzdbeeJFYGzExVQPk/MrzsD5FWfgitMlM+9++9n4/Zfn4NLzp+Hc8qnYcts1snVDWw9jZuUZeM/55RAEAVsPJvCZ36/CHbWX45PvPQ8jowIqz8rsYv1vc2bi1qe24KJzz8bgSBJTJk7Af1z9LnF5enfoP3x5Dv7w5Tn4xG9ewo7DYw3hamtm4o7ay/HclkPiCMHLf/gvuPi8aTg1NIp7XooidvQENu/vxfIf/gvaIvswODyKwZEk5l5Yiat8M/Cdj16EJa/ExFFcn/jOP2HOOytx/Yd9SApjo1r29A/hg4tWyNLzrX+uwmhSwF9e3Y1LzpuGX/7b+1BzYSWu++cqLDk9gNScd3rFMVbW/XcAX//jGlx6fjnunH8Flr9xCOeVT0V3/xCantuGK6umo/fUMHYf78e/f2g2fvDIBtz+hfdi6qQJ+Ngl54ptob5y1Tsx98JK3LMyireOnMB/fPwisTfXvV+rwdTJE1B55hRcPrMCX7h7NTbu68Xv/s8V2H2sH22RLnGE1GvnzsSj68fHwLnxmovx9Q9eiJ6TQzhjykT84pk38feNB/AB33Q8fP0HcPOTW8SeRh9+1zn41HvPx5evnIXInh5xLplLzpuGbYf60PylyzFxggeH+wZw5ws7ZONO3PDRapxdNglvL5+a0fPntcaPI7T1MPb3nMLLbx2D721n4cZPXIwFj23C2l3d+PC7zsGfvzkPS9d34b+fGOt6u/LHH0VP/xBuf2YrLjm/HDd96hJc/rMXAIzdvD/3/gtw70tRXOCdin9sHmuk+9GL34aV2zN7uj3/ww/jnpVRnDF5Ijbu68U5Z09RHKH0E5e+Hd/52EWYWXmGYhu1qnPOEhsaf+79F+DcaWXioGIv/vijOGPyRHz+7lVZG7N++yPVuPcl+Tg+X/S/AzMrz8SmfXFcPtMr61lzdtkkbP7ZJ8a2v/0Imp7bLhvU7atXvRMjowL+/Z+rcNG5Z4tj19z62UtxcnAkr16H7/CekTFC9sQJHlkPm8VffB+e3LBfHLBy6uQJslnRAeDT7ztP/F1SKs+cjG/+UxWe2rAf3/jghXho7V5cVTUjo1Gokh8F341dx06qtsW6fGaFand4AGj5eo1soEQl4R99RNJDEag4Y7LqQJUpb5tWhpHRJHr6h/HNf5qN57YcxOwZZ6HpS5fjW39dhxlnlSF+akjM5y4692zMnnGWYmPip777IXxew/hb2Xz5ylnweDz4zPvOx/fQKVt2fsXUjBGFzzm7LKNX3y2fvRS3S6aqCP3nv+DvGw/gD6fzpQevu0qxc8T1H67Cfa9kb0h85pSJmhr8KvnQRTNwVdWMrD3T7OKaRsENDQ3o7u5GW1ub+F5NTQ0CgQCamppknx0cHMTg4PhJkUgkMGvWLMMbBfeeGsbn71qF3cf7se32T2LqZGMbQ9mhf2gEhxODqDons4THTFv296J/aBSXz6zQdRzj/UMYTQqYcXomaa0EQdA8tPfqncfQPzSKwHvOzblOMilgx5E+vPvcaZgwwYOB4VFs2d+LOe+slHU5zSddgiBgJCkozpScGBhGeVr36OHRJAQBmDJpgq7vm9oXoG/483T9QyM4c8okJAaG0Tcwgnd4M8dHWrn9CE4NjSJ46dvxWuw49vWcwpevlFfbDgyP4kD8FLYeTOCsskn42MXn6krHW4f7sPt4P2JHT+DYiUH892cuFZcNjyazzjytpqu7H794disaPlItm309nSAI2H28H5VnTkZkTw8+WD0DZ06ZhJ6TQ1izqxuB95yLxMAIpp9+KOk5OYRJEz2YNnUyRkaT2B8/hQtnnIVkUsCECR4MjSQxeeJYz5NsU6sMjoxi28E+TD9rCmZNH5uEMrV+LjsO9+HB1/fgex9/F942Tds1teNwHyZ4PLhwxpkYTQqYOnkihkaS8HjGxrGZcfomXXHGZGw/1Id3zjgT5VMnQxAEjCYFnBgcQcUZkzE8KmDKpMzf4uTgiOy7Hj8xiL+9tgeXXlCOay47L+v36xsYVh0y4OTgCDr29uBD1efI1n15x1F8/+FOLP/hv+C8iqkYGkliX0+/OI5Vb/8wDvcN4NxpZRgcSWL6WVMQO3oSkyd6ENp6GHVzZ2EkmcS50zJLoPuHRhDaehgfffe5qDhzMkaTY9PZtK3vws2fvRSTJ45dq6eGR3HmFPnvO5oUkBSUr/+U3lPDWBM7jo9efK54LN863IeDvQOYNf1MvHkwgcSpYQyNJvH1D1yIhY9twgXeM3DDR6vF9i+rb/q44rWqZGgkiaHRJFZuP4LvPdSJGWdNQeQWY5uC6GkUXJQBzc9+9jPcdtttGdswOqAhIiIqBnofeqRODY1i26EEyiZNxKUXGHuPLcpeTtXV1YjH47L34vE45s3LHD2xsbERvb294r+uLu0jchIREZWaQkpjz5gyEXPeWWl4MKOXawIav9+f0QA4FouJjYSlysrKUF5eLvtHRERExcs1AU0gEAAAMagJh8Pw+/3w+Xx2JouIiIgcwDW9nAAgFAqhqakJNTU1iEQiaG/XPu8QERERFS/XNAouhFlTHxAREZF5irJRMBEREVE2DGiIiIjI9RjQEBERkesxoCEiIiLXY0BDRERErseAhoiIiFyPAQ0RERG5HgMaIiIicj0GNEREROR6rpr6IF+pwZATiYTNKSEiIiKtUvdtLZMalERA09fXBwCYNWuWzSkhIiIivfr6+lBRUaH6mZKYyymZTOLAgQOYNm0aPB6PodtOJBKYNWsWurq6OE+UDXj87cNjby8ef/vw2FtHEAT09fXhggsuwIQJ6q1kSqKEZsKECZg5c6ap+ygvL+eJbSMef/vw2NuLx98+PPbWyFUyk8JGwUREROR6DGiIiIjI9RjQFKisrAw//elPUVZWZndSShKPv3147O3F428fHntnKolGwURERFTcWEJDRERErseAhoiIiFyPAQ0RERG5HgOaPMViMTQ0NKC1tRULFy60OzlFIxwOo7q6Gh6PB3V1dbJlasc832WkrKamBvF4XPybx95aHR0dCIfD4t88/ubr6OjAwoUL0dzcjLq6OsRiMXEZj79LCJQXn88nRCIRQRAEIRQKCYFAwOYUuV9PT49QX18vRKNRIRKJCF6vV6ivrxeXqx3zfJdRppaWFgGA0NPTI77HY2+NSCQiBAIBIRQKyd7n8Tef1+sVXxt1jHn8rcWAJg+hUEh28guCIAAQotGoTSkqDm1tbbK/m5qaBL/fLwiC+jHPdxll6unpyQhoeOytkQri048Pj7/5enp6ZOd8KrAUBB5/N2GVUx46Ojowd+5c2Xs+n09WREz61dbWyv72er3w+XwA1I95vsso06JFi1BfXy97j8feGnV1dWhsbBTP+RQef/N5vV74/X7U1dUhHo9j0aJFYhURj797lMRcTkaLRqPwer2y97xeL6LRqD0JKlKhUAgNDQ0A1I95PB7PaxnJhcNhzJ8/P+N9HnvzhcNhxGIxRKNR1NXVie056uvrefwt0t7ejpqaGlRWVqKtrQ2BQAAAz383YUBDjhSLxTB9+nQxUyHzhUIhNDU12Z2MktTR0QGfz4eWlhbx75qaGp7/Furu7kYgEEAsFkNdXR0ikQj8fr/dySIdWOWUh+rqalkPEACIx+OYN2+ePQkqQk1NTWLmDqgf83yX0bjm5mY0NjYqLuOxt4b0ad7v98Pr9Yq9/nj8zRcMBtHU1IRQKITa2lpcffXVAHj+uwkDmjz4/X5Zlz5grESB0bwxlLo4qh3zfJfRuKVLl6KqqgqVlZWorKwEAFRVVaG5uZnH3gJKx2r69OmYPn06j78FYrEYuru7xaDyvvvuQzweRzwe5/F3E7tbJbuVz+cTW6uHQiGxNw4Vpq2tTezmKAiC2FtAENSPeb7LSBkUum3z2JtL2sVXEMa6Ead+Ax5/80HSA6mnp0fWQ4nH3x3YhiZPqfYGNTU1iEQiaG9vtztJrhcOhzMG0wMA4fT8qWrHPN9lpA2PvflCoRAWLlyIYDCIaDSK9vZ2scSAx998ZhxjHn9rcbZtIiIicj22oSEiIiLXY0BDRERErseAhoiIiFyPAQ0RERG5HgMaIiIicj0GNEREROR6DGiIiIjI9RjQEJEoNSmix+NBc3Nzxlw0ZgoGg1i2bJll+ytUa2srKisrLT1GRJQdB9YjIpnW1lY0NDRAmjWkZoOWTqBYqPRthsNhzJ0719B9mCkej6OyshI9PT2uSTNRMWMJDRGpisfjilNSGL3NQCDgqsDATWklKgUMaIhIVTgcRiwWw6JFi9DR0SG+19zcjGAwiIaGBgDAsmXLxGqj6upqNDc3AwCam5uxbNkyNDQ0iO+lb7OjowN1dXVobW0V99vR0YHm5ma0trairq5OnLk4HA6jpqYGy5YtQ11dHSorKxEOhzPSnO0zra2t8Hg8iMViiMViCAaDCAaDsvVSM75XV1ejtbVVnGessrJSPAYpjz76KGpqalBZWSmrMtNzjIjIAHbOjElEztPS0iKkZw2QzL4djUaFBQsWiMu8Xq/Q1tYm9PT0CACEBQsWCNFoVIhEIkI0GhVnLU4tV9qmIAiC3+8XmpqaxM9KZzsOhUKyvwGIn12wYIHiLMZqn4FkZuWWlhYhEAiIy3w+n/j9QqGQAECcBXvBggVCfX29bDstLS2CIAhCU1OT+J30HCMiMgZn2yYiXZYtW4ZYLCaWLjQ2NsrawsyfPx8+n0/8fCQSAQCsX78ewFh1k1J1jXSd1tZWzJ07V/w7EAiI+66trYXX64Xf7wcAzJs3T7ExsZbPKPF6vZg3bx4AiGlIbae6uhptbW2yz1977bUAgAULFmDRokVi6ZOeY0REhWNAQ0S6RKNRBINB1NfXa/p8qr1MqlpH6z7S+Xw+sdpJSktbFqvau/h8PnR3d+s+RkRUOLahISJNuru7AYwFB+mlFOntSlJisRjq6urQ1tameHNPbTNddXW1YvCSKikxWrZ06BWPx8WeWlqPEREZgwENEWmSGm9l/vz5CIfDYgPeZcuWZQ0IpI11lQIU6Rgu0tf19fWIxWJiEBCPxxGPx8Wqp2zbyJX2FK/XK247FAqho6NDrJJS2p70vWzfNR6Pw+fzwe/36zpGRGQQuxvxEJFzRCIRwe/3iw1qU4126+vrBb/fL4RCIUEQxhrAer1ewev1io1i29raBABCfX29uF5PT4/g8/kEv98vtLW1CX6/X6itrc3YZiQSEbxerxAIBMR1I5GIUFtbK7S0tMjSkmqom9pPbW2trOGuls+0tLQIXq9X3H4gEBBCoZC4Xm1trdDT0yM29E3tPxAICF6vV9xOfX29Yhr1HCMiMgYH1iMiIiLXY5UTERERuR4DGiIiInI9BjRERETkegxoiIiIyPUY0BAREZHrMaAhIiIi12NAQ0RERK7HgIaIiIhcjwENERERuR4DGiIiInI9BjRERETkev8f1N0VIb1fkS4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A useful debugging strategy is to plot the loss as a function of\n",
    "# iteration number:\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c70c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.917500\n",
      "validation accuracy: 0.892857\n"
     ]
    }
   ],
   "source": [
    "# Write the LinearSVM.predict function and evaluate the performance on both the\n",
    "# training and validation set\n",
    "y_train_pred = classifier.predict(X_train)\n",
    "print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "print('validation accuracy: %f' % (np.mean(y_test == y_test_pred), ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
